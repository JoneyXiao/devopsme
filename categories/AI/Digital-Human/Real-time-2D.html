<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.23" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.88" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Real-time 2D","image":[""],"datePublished":"2025-06-21T18:30:00.000Z","dateModified":"2025-07-03T03:17:24.000Z","author":[{"@type":"Person","name":"DevOpsMe","url":"https://github.com/JoneyXiao/devopsme"}]}</script><meta property="og:url" content="https://vuepress-theme-hope-docs-demo.netlify.app/devopsme/categories/AI/Digital-Human/Real-time-2D.html"><meta property="og:site_name" content="DevOpsMe"><meta property="og:title" content="Real-time 2D"><meta property="og:description" content="LLM 开源社区现有状态，非常活跃，大家开发 AI 原生应用时，可以参考选择。请以最新数据为准。 带着兴趣和疑问来听这个分享。分享完后，期待能够动手实践。 开源 LM 国内 阿里云 ，多模态 Qwen 2.5 VL, Qwen2.5-Omni , DeepSeek-V3, 多模态目前还未有 智谱 AI GLM-4，多模态 VisualGLM-6B, C..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2025-07-03T03:17:24.000Z"><meta property="article:tag" content="ai agent"><meta property="article:tag" content="adh"><meta property="article:tag" content="live 2D"><meta property="article:tag" content="real-time-2d"><meta property="article:tag" content="digital-human"><meta property="article:tag" content="ai"><meta property="article:published_time" content="2025-06-21T18:30:00.000Z"><meta property="article:modified_time" content="2025-07-03T03:17:24.000Z"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&family=Lora:ital,wght@0,400..700;1,400..700&display=swap" rel="stylesheet"><link rel="icon" href="/devopsme/favicon.ico"><title>Real-time 2D | DevOpsMe</title><meta name="description" content="LLM 开源社区现有状态，非常活跃，大家开发 AI 原生应用时，可以参考选择。请以最新数据为准。 带着兴趣和疑问来听这个分享。分享完后，期待能够动手实践。 开源 LM 国内 阿里云 ，多模态 Qwen 2.5 VL, Qwen2.5-Omni , DeepSeek-V3, 多模态目前还未有 智谱 AI GLM-4，多模态 VisualGLM-6B, C...">
    <link rel="preload" href="/devopsme/assets/style-BBLX0-hQ.css" as="style"><link rel="stylesheet" href="/devopsme/assets/style-BBLX0-hQ.css">
    <link rel="modulepreload" href="/devopsme/assets/app-D1k-6CWc.js"><link rel="modulepreload" href="/devopsme/assets/Real-time-2D.html-DsFlZlg1.js"><link rel="modulepreload" href="/devopsme/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/devopsme/assets/index.html-BNnVqtam.js" as="script"><link rel="prefetch" href="/devopsme/assets/portfolio.html-C5xbhugX.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-BOlLDnYN.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-pgeDwzcM.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-D4sitiSV.js" as="script"><link rel="prefetch" href="/devopsme/assets/disable.html-CCs3J1d8.js" as="script"><link rel="prefetch" href="/devopsme/assets/encrypt.html-BGTJv-V0.js" as="script"><link rel="prefetch" href="/devopsme/assets/layout.html-CETtbKaB.js" as="script"><link rel="prefetch" href="/devopsme/assets/markdown.html-BF2ucWD0.js" as="script"><link rel="prefetch" href="/devopsme/assets/page.html-DxRk9ZBn.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-B9ga08eX.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-BLah-j3T.js" as="script"><link rel="prefetch" href="/devopsme/assets/explain-ci-cd.html-SKjDrU51.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-BULemOVA.js" as="script"><link rel="prefetch" href="/devopsme/assets/cloud-providers.html-D_1x7-tF.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-DIuEoohh.js" as="script"><link rel="prefetch" href="/devopsme/assets/docker-kubernetes.html-CkJXOhKW.js" as="script"><link rel="prefetch" href="/devopsme/assets/How-to-Ask-Questions-the-Smart-Way.html-CyuTtUdy.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-CzWW_I27.js" as="script"><link rel="prefetch" href="/devopsme/assets/sre-vs-devops.html-DE6ybVcT.js" as="script"><link rel="prefetch" href="/devopsme/assets/what-is-devops.html-BUlM09Yl.js" as="script"><link rel="prefetch" href="/devopsme/assets/ansible-advanced.html-l9prIR-2.js" as="script"><link rel="prefetch" href="/devopsme/assets/ansible-basics.html-BzNeaEJm.js" as="script"><link rel="prefetch" href="/devopsme/assets/ansible-troubleshooting.html-C1QNyksU.js" as="script"><link rel="prefetch" href="/devopsme/assets/infrastructure-as-code.html-DND-2R_F.js" as="script"><link rel="prefetch" href="/devopsme/assets/observability.html-k_j2FHks.js" as="script"><link rel="prefetch" href="/devopsme/assets/practical-task.html-BCbnKC4V.js" as="script"><link rel="prefetch" href="/devopsme/assets/Glossary.html-Cib0XVxS.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-BM8DrXl_.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Advanced-Concepts.html-DUFXr3vG.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Architecture.html-BoSG8Xwy.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Core-Certified-Power-User.html-Bq7tgnbc.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Inputs.html-kGByHB8W.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Installation-Provision.html-CSNmntNL.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Searching-Reporting.html-BzLLRixU.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Visualizing.html-BR3AGZ-r.js" as="script"><link rel="prefetch" href="/devopsme/assets/splunk-interview-questions.html-tOEvJsip.js" as="script"><link rel="prefetch" href="/devopsme/assets/terraform-interview-questions.html-DAx3UEPL.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-BRKWDnTk.js" as="script"><link rel="prefetch" href="/devopsme/assets/baz.html-DJqc6E_Q.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-CTSMn729.js" as="script"><link rel="prefetch" href="/devopsme/assets/ray.html-sxASrIG5.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-BOs6y_4M.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-CVw7FOwK.js" as="script"><link rel="prefetch" href="/devopsme/assets/Azure.html-C-hbEKYa.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-DSs56hlS.js" as="script"><link rel="prefetch" href="/devopsme/assets/AWS-Overview.html-DTWijjSp.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-DFJwRkZZ.js" as="script"><link rel="prefetch" href="/devopsme/assets/404.html-DXySPKlI.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-C8bShl8p.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-CEZV42xV.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-COr6SUJK.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-Br6FBSsV.js" as="script"><link rel="prefetch" href="/devopsme/assets/photoswipe.esm-DXWKOczD.js" as="script"><link rel="prefetch" href="/devopsme/assets/giscus-1zs_z9NH.js" as="script"><link rel="prefetch" href="/devopsme/assets/index-B-M8YVCw.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/devopsme/" aria-label="Take me home"><img class="vp-nav-logo light" src="/devopsme/assets/image/logos--web-dev-icon-light.svg" alt><img class="vp-nav-logo dark" src="/devopsme/assets/image/logos--web-dev-icon-dark.svg" alt><span class="vp-site-name hide-in-pad">DevOpsMe</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Categories"><!--[--><iconify-icon class="vp-icon" icon="bx:category" height="1em" sizing="height"></iconify-icon>Categories<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Categories</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/cloud/" aria-label="Cloud"><!--[--><iconify-icon class="vp-icon" icon="ic:baseline-cloud" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->Cloud<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/devopsme/categories/AI/" aria-label="AI"><!--[--><iconify-icon class="vp-icon" icon="streamline-flex:ai-chip-robot-remix" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->AI<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/splunk/" aria-label="Splunk"><!--[--><iconify-icon class="vp-icon" icon="ep:arrow-right-bold" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->Splunk<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/general/" aria-label="General"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:universal-access" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->General<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/containers/" aria-label="Containers"><!---->Containers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/ci-cd/" aria-label="CICD"><!---->CICD<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/infrastructure/" aria-label="Infrastructure"><!---->Infrastructure<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/monitoring/" aria-label="Monitoring"><!---->Monitoring<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/scripting/" aria-label="Scripting"><!---->Scripting<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/terraform/" aria-label="Terraform"><!---->Terraform<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/devopsme/portfolio.html" aria-label="About Me"><!--[--><iconify-icon class="vp-icon" icon="qlementine-icons:resume-16" height="1em" sizing="height"></iconify-icon><!--]-->About Me<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/JoneyXiao/devopsme" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:none;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:block;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><div id="docsearch-container" style="display:none;"></div><div><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"><svg width="15" height="15" class="DocSearch-Control-Key-Icon"><path d="M4.505 4.496h2M5.505 5.496v5M8.216 4.496l.055 5.993M10 7.5c.333.333.5.667.5 1v2M12.326 4.5v5.996M8.384 4.496c1.674 0 2.116 0 2.116 1.5s-.442 1.5-2.116 1.5M3.205 9.303c-.09.448-.277 1.21-1.241 1.203C1 10.5.5 9.513.5 8V7c0-1.57.5-2.5 1.464-2.494.964.006 1.134.598 1.24 1.342M12.553 10.5h1.953" stroke-width="1.2" stroke="currentColor" fill="none" stroke-linecap="square"></path></svg></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="vp-icon" icon="fa6-solid:book" width="1em" height="1em" sizing="both"></iconify-icon><span class="vp-sidebar-title">Docs</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="ic:baseline-cloud" width="1em" height="1em" sizing="both"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/devopsme/categories/cloud/" aria-label="Cloud"><!---->Cloud<!----></a><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><iconify-icon class="vp-icon" icon="streamline-flex:ai-chip-robot-remix" width="1em" height="1em" sizing="both"></iconify-icon><a class="route-link route-link-active auto-link vp-sidebar-title no-external-link-icon" href="/devopsme/categories/AI/" aria-label="AI"><!---->AI<!----></a><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><a class="route-link route-link-active auto-link vp-sidebar-title no-external-link-icon" href="/devopsme/categories/AI/Digital-Human/" aria-label="Digital Human"><!---->Digital Human<!----></a><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/devopsme/categories/AI/Digital-Human/Real-time-2D.html" aria-label="Real-time 2D"><!---->Real-time 2D<!----></a></li></ul></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="ep:arrow-right-bold" width="1em" height="1em" sizing="both"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/devopsme/categories/splunk/" aria-label="Splunk"><!---->Splunk<!----></a><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:universal-access" width="1em" height="1em" sizing="both"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/devopsme/categories/general/" aria-label="General"><!---->General<!----></a><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">CICD</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Containers</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Infrastructure</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Monitoring</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Scripting</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Terraform</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Real-time 2D</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/JoneyXiao/devopsme" target="_blank" rel="noopener noreferrer">DevOpsMe</a></span><span property="author" content="DevOpsMe"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">6/21/25</span><meta property="datePublished" content="2025-06-21T18:30:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 15 min</span><meta property="timeRequired" content="PT15M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color2" role>ai</span><span class="page-category-item color3" role>digital-human</span><!--]--><meta property="articleSection" content="ai,digital-human"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color2" role>ai</span><span class="page-tag-item color3" role>digital-human</span><span class="page-tag-item color4" role>real-time-2d</span><span class="page-tag-item color2" role>live 2D</span><span class="page-tag-item color7" role>adh</span><span class="page-tag-item color6" role>ai agent</span><!--]--><meta property="keywords" content="ai,digital-human,real-time-2d,live 2D,adh,ai agent"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><p>LLM 开源社区现有状态，非常活跃，大家开发 AI 原生应用时，可以参考选择。请以最新数据为准。</p><p>带着兴趣和疑问来听这个分享。分享完后，期待能够动手实践。</p><h2 id="开源-lm" tabindex="-1"><a class="header-anchor" href="#开源-lm"><span>开源 LM</span></a></h2><h3 id="国内" tabindex="-1"><a class="header-anchor" href="#国内"><span>国内</span></a></h3><ul><li>阿里云 <!---->，多模态 Qwen 2.5 VL, Qwen2.5-Omni</li><li><!---->, DeepSeek-V3, 多模态目前还未有</li><li>智谱 AI GLM-4，多模态 VisualGLM-6B, CogVLM-17B</li><li>腾讯云 Hunyuan-MoE-A52B，多模态 Hunyuan-DiT，Hunyuan3D 2.0</li></ul><h3 id="国外" tabindex="-1"><a class="header-anchor" href="#国外"><span>国外</span></a></h3><ul><li>Meta Llama4, 多模态 Llama4, Llama 4 Scout, Llama 4 Maverick</li><li>Mistral Small 3.1, 多模态 Mistral Small 3.1</li><li>Google Gemma3, 多模态 Gemma3</li><li>xAI Grok-1, Grok-2, 多模态目前还未有</li></ul><h2 id="开源-lm-发布平台" tabindex="-1"><a class="header-anchor" href="#开源-lm-发布平台"><span>开源 LM 发布平台</span></a></h2><ul><li><a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">Hugging Face Hub</a></li><li><a href="https://www.modelscope.cn/models" target="_blank" rel="noopener noreferrer">ModelScope</a></li><li><a href="https://ollama.com/search" target="_blank" rel="noopener noreferrer">Ollama</a></li></ul><h2 id="开源-lm-部署工具" tabindex="-1"><a class="header-anchor" href="#开源-lm-部署工具"><span>开源 LM 部署工具</span></a></h2><table><thead><tr><th style="text-align:left;">主流 LM 部署工具</th><th style="text-align:left;">其它 LM 部署工具</th></tr></thead><tbody><tr><td style="text-align:left;">- <a href="https://github.com/ollama/ollama" target="_blank" rel="noopener noreferrer">Ollama</a></td><td style="text-align:left;">- <a href="https://github.com/ggml-org/llama.cpp" target="_blank" rel="noopener noreferrer">llama.cpp</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer">vLLM</a></td><td style="text-align:left;">- <a href="https://github.com/Mozilla-Ocho/llamafile" target="_blank" rel="noopener noreferrer">llamafile</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">Hugging Face Transformers</a></td><td style="text-align:left;">- <a href="https://github.com/nomic-ai/gpt4all" target="_blank" rel="noopener noreferrer">GPT4All</a></td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;">- <a href="https://github.com/sgl-project/sglang" target="_blank" rel="noopener noreferrer">SGLang</a></td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;">- <a href="https://github.com/mlc-ai/web-llm" target="_blank" rel="noopener noreferrer">WebLLM</a></td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;">- <a href="https://github.com/ModelTC/lightllm" target="_blank" rel="noopener noreferrer">LightLLM</a></td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;">- <a href="https://github.com/microsoft/BitNet" target="_blank" rel="noopener noreferrer">BitNet</a></td></tr></tbody></table><h2 id="开源-ai-agent-开发框架" tabindex="-1"><a class="header-anchor" href="#开源-ai-agent-开发框架"><span>开源 AI Agent 开发框架</span></a></h2><blockquote><p>2024 年 AI Agent 开发领域以开源社区为主，2025 年大厂开始发力，在我看来，AI Agent 开发框架会以开源社区为主。<br><a href="https://learn.microsoft.com/en-us/azure/ai-foundry/agents/overview" target="_blank" rel="noopener noreferrer">Azure AI Foundry Agent Service</a> 是一个将模型、工具、框架和治理机制整合为统一平台的系统，用于构建智能体。</p></blockquote><table><thead><tr><th style="text-align:left;">通⽤ AI Agent 开发框架</th><th style="text-align:left;">RAG 开发框架</th><th style="text-align:left;">低代码开发⼯具</th><th style="text-align:left;">类 Manus 开发框架</th></tr></thead><tbody><tr><td style="text-align:left;">- <a href="https://github.com/langchain-ai/langgraph" target="_blank" rel="noopener noreferrer">LangChain + LangGraph</a></td><td style="text-align:left;">- <a href="https://github.com/run-llama/llama_index" target="_blank" rel="noopener noreferrer">LlamaIndex</a></td><td style="text-align:left;">- <a href="https://github.com/langgenius/dify" target="_blank" rel="noopener noreferrer">Dify</a></td><td style="text-align:left;">- <a href="https://github.com/FoundationAgents/OpenManus" target="_blank" rel="noopener noreferrer">OpenManus</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/crewAIInc/crewAI" target="_blank" rel="noopener noreferrer">CrewAI</a></td><td style="text-align:left;">- <a href="https://github.com/microsoft/graphrag" target="_blank" rel="noopener noreferrer">GraphRAG</a></td><td style="text-align:left;">- <a href="https://github.com/labring/FastGPT" target="_blank" rel="noopener noreferrer">FastGPT</a></td><td style="text-align:left;">- <a href="https://github.com/camel-ai/owl" target="_blank" rel="noopener noreferrer">OWL</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/openai/openai-agents-python" target="_blank" rel="noopener noreferrer">Agent SDK</a></td><td style="text-align:left;">- <a href="https://github.com/chatchat-space/Langchain-Chatchat" target="_blank" rel="noopener noreferrer">LangChain-Chatchat</a></td><td style="text-align:left;">- <a href="https://github.com/FlowiseAI/Flowise" target="_blank" rel="noopener noreferrer">Flowise</a></td><td style="text-align:left;">- <a href="https://github.com/femto/minion-agent" target="_blank" rel="noopener noreferrer">Minion-Agent</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/Significant-Gravitas/AutoGPT" target="_blank" rel="noopener noreferrer">AutoGPT Platform</a></td><td style="text-align:left;"></td><td style="text-align:left;">- <a href="https://github.com/n8n-io/n8n" target="_blank" rel="noopener noreferrer">n8n</a></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/microsoft/autogen" target="_blank" rel="noopener noreferrer">AutoGen</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/FoundationAgents/MetaGPT" target="_blank" rel="noopener noreferrer">MetaGPT</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/camel-ai/camel" target="_blank" rel="noopener noreferrer">Camel</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/yoheinakajima/babyagi" target="_blank" rel="noopener noreferrer">BabyAGI</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/Link-AGI/AutoAgents" target="_blank" rel="noopener noreferrer">AutoAgents</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://google.github.io/adk-docs/" target="_blank" rel="noopener noreferrer">Google- ADK</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://strandsagents.com/latest/" target="_blank" rel="noopener noreferrer">AWS - Strands Agents</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr></tbody></table><h2 id="开源数字人项目" tabindex="-1"><a class="header-anchor" href="#开源数字人项目"><span>开源数字人项目</span></a></h2><table><thead><tr><th style="text-align:left;">⾮实时数字⼈</th><th style="text-align:left;">2D 实时数字人</th><th style="text-align:left;">3D 实时数字人</th></tr></thead><tbody><tr><td style="text-align:left;">- <a href="https://github.com/antgroup/echomimic_v2" target="_blank" rel="noopener noreferrer">EchoMimic V2</a></td><td style="text-align:left;">- <a href="https://github.com/wan-h/awesome-digital-human-live2d" target="_blank" rel="noopener noreferrer">ADH</a></td><td style="text-align:left;">- <a href="https://github.com/HumanAIGC-Engineering/OpenAvatarChat" target="_blank" rel="noopener noreferrer">阿里达摩院 OpenAvatarChat</a><br><a href="https://www.openavatarchat.ai/playground" target="_blank" rel="noopener noreferrer">Playground</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/duixcom/Duix.Heygem" target="_blank" rel="noopener noreferrer">Heygem</a></td><td style="text-align:left;">- <a href="https://github.com/lipku/livetalking" target="_blank" rel="noopener noreferrer">LiveTalking</a></td><td style="text-align:left;">- <a href="https://github.com/Henry-23/VideoChat" target="_blank" rel="noopener noreferrer">VideoChat</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/jixiaozhong/Sonic" target="_blank" rel="noopener noreferrer">Sonic</a></td><td style="text-align:left;">- <a href="https://github.com/anliyuan/Ultralight-Digital-Human" target="_blank" rel="noopener noreferrer">Ultralight-Digital-Human</a><br>(2.5D - AI 模型实时生成)</td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/KwaiVGI/LivePortrait" target="_blank" rel="noopener noreferrer">LivePortrait</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/xszyou/fay" target="_blank" rel="noopener noreferrer">Fay</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/OpenTalker/SadTalker" target="_blank" rel="noopener noreferrer">SadTalker</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/bytedance/LatentSync" target="_blank" rel="noopener noreferrer">LatentSync</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/JOY-MM/JoyGen" target="_blank" rel="noopener noreferrer">JoyGen</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr></tbody></table><h2 id="商业-3d-数字人" tabindex="-1"><a class="header-anchor" href="#商业-3d-数字人"><span>商业 3D 数字人</span></a></h2><ul><li><p><a href="https://blogs.nvidia.cn/blog/digital-humans-ace-generative-ai-microservices/" target="_blank" rel="noopener noreferrer">Nvidia ACE</a></p><!----> 是目前最为逼真的数字人服务，支持实时交互。当然，价格不菲。视频中展示了非常多的应用场景，还有 <a href="https://build.nvidia.com/nvidia/digital-humans-for-customer-service" target="_blank" rel="noopener noreferrer">在线 demo</a> 可以体验。<p><a href="https://www.bilibili.com/video/BV1Dz42187yB/" target="_blank" rel="noopener noreferrer">B 站上更完整的 Nvidia 数字人演示视频</a></p><!--[--><div class="bilibili-desc"><a class="sr-only" href="https://player.bilibili.com/player.html?bvid=BV1Dz42187yB&amp;t=0&amp;autoplay=0">A BiliBili video</a></div><iframe src="https://player.bilibili.com/player.html?bvid=BV1Dz42187yB&amp;t=0&amp;autoplay=0" title="A BiliBili video" class="bilibili-iframe" allow="accelerometer; autoplay; clipboard-write; encrypted-media; fullscreen; gyroscope; picture-in-picture" style="width:100%;height:0;"></iframe><div style="display: flex;align-items: center;justify-content: center;height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);--icon-size: 48px;display: inline-block;width: var(--icon-size);height: var(--icon-size);background-color: currentcolor;-webkit-mask-image: var(--loading-icon);mask-image: var(--loading-icon)"></span></div><!--]--></li><li><p><a href="https://www.metahuman.com/en-US" target="_blank" rel="noopener noreferrer">Metahuman</a>。创建并驱动完全定制的高度逼真 3D 数字人。</p></li></ul><h2 id="adh-2d-实时数字人" tabindex="-1"><a class="header-anchor" href="#adh-2d-实时数字人"><span><!----></span></a></h2><p>开源项目 <a href="https://github.com/wan-h/awesome-digital-human-live2d" target="_blank" rel="noopener noreferrer">awesome-digital-human-live2d</a>，缩写为 ADH，是国内优秀开发者<!---->老师在 2024 年开发的。ADH 项目分成后端和前端两部分。<!---->。可以本地部署开源大模型，也可以使用<a href="https://bailian.console.aliyun.com/?tab=model#/model-market" target="_blank" rel="noopener noreferrer">阿里云百炼模型广场</a>。</p><figure><img src="/devopsme/assets/adh-arch-high-level-DbnZJ3XR.png" alt="ADH 架构" tabindex="0" loading="lazy"><figcaption>ADH 架构</figcaption></figure><h3 id="部署-adh-前后端" tabindex="-1"><a class="header-anchor" href="#部署-adh-前后端"><span>部署 ADH 前后端</span></a></h3><!----><p>ADH 后端就是一个基于 FastAPI 开发的服务，它的主要作用是集成外部的一些基础服务（包括 ASR、TTS、LLM 三类）和外部的 AI Agent，暴露 RESTful API 给前端使用。ADH 前端遵循 BFF 架构模式（Backend for Frontend），而支持 BFF 架构前端的理想选择就是微服务，主要是基于 RESTful API 的微服务。而使用 Python 开发微服务的首选开发框架就是 FastAPI。</p><p>ADH 后端按照目录结构呈现微单向依赖关系，代码采用标准的 OOP 面向对象风格编写。</p><figure><img src="/devopsme/assets/adh-backend-depends-uA9GwTy2.png" alt="ADH 后端目录结构单向依赖关系" tabindex="0" loading="lazy"><figcaption>ADH 后端目录结构单向依赖关系</figcaption></figure><p>ADH 后端部署的步骤：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Python 3.10 on 22.04 and Python 3.12 on 24.04 by default</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> apt</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python3</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python3-pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python3-dev</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">curl</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -LsSf</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://astral.sh/uv/install.sh</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> | </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sh</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># FFmpeg</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> apt</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> update</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> apt</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ffmpeg</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Clone ADH</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> clone</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/wan-h/awesome-digital-human-live2d.git</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> awesome-digital-human-live2d</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Init a uv project</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> init</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 3.10</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Update `pyproject.toml` to use Tsinghua University&#39;s PyPI mirror</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Add the following section at the beginning of the file:</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># [[tool.uv.index]]</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># url = &quot;https://pypi.tuna.tsinghua.edu.cn/simple&quot;</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># default = true</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Install dependencies</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> add</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> $(</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">cat</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> requirements.txt</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Create the main config file (port: 8002)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> configs</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">cp</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> config_template.yaml</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> config.yaml</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Run the ADH backend server</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~/awesome-digital-human-live2d</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> main.py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><!----><p>ADH 前端是一个标准的 H5 页面，而且支持被内嵌在其他 H5 页面中，例如微信小程序。Next.js 应用的架构遵循标准的 BFF（Backend for Frontend）架构模式。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Install Node.js(v22.16.0) https://nodejs.org/en/download</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">npm</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -g</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> next</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">npm</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -g</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> heroui-cli</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">corepack</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> enable</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pnpm</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Clone ADH</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> clone</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/wan-h/awesome-digital-human-live2d.git</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> awesome-digital-human-live2d/web</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Install dependencies</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pnpm</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Update frontend configs</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># NEXT_PUBLIC_SERVER_IP=&quot;&lt;ADH backend server IP&gt;&quot;</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># NEXT_PUBLIC_SERVER_PORT=&quot;&lt;ADH backend server port&gt;&quot;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">copy</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .env_template</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .env</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Run the ADH frontend server</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pnpm</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> build</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pnpm</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> start</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><!----><p>在 UI 设置界面配置 AI Agent，引擎选择 &quot;OpenAI&quot;，引擎配置我用的是阿里云百炼模型广场的 <code>qwen3-8b</code>。TTS 默认使用的免费服务是 <a href="https://edge-tts.com/" target="_blank" rel="noopener noreferrer">EdgeTTS</a>，点击这个链接可以体验。</p><figure><img src="/devopsme/assets/adh-ui-Capo3slK.png" alt="ADH UI" tabindex="0" loading="lazy"><figcaption>ADH UI</figcaption></figure><h3 id="使用-agent-sdk-开发-ai-agent-对接-adh" tabindex="-1"><a class="header-anchor" href="#使用-agent-sdk-开发-ai-agent-对接-adh"><span>使用 Agent SDK 开发 AI Agent 对接 ADH</span></a></h3><p>目前 ADH 后端已经实现了与 Dify、FastGPT 开发的 AI Agent 的对接。我们将实现与 Agent SDK 开发的 AI Agent 的对接。下文提到的外部 AI Agent 的代码文件在 GitHub 仓库 <a href="https://github.com/JoneyXiao/adh-ai-agent" target="_blank" rel="noopener noreferrer">adh-ai-agent</a> 中。</p><p><a href="https://openai.github.io/openai-agents-python/" target="_blank" rel="noopener noreferrer">Agent SDK</a> 是 OpenAI 在 <a href="https://openai.com/index/new-tools-for-building-agents/" target="_blank" rel="noopener noreferrer">2025 年 3 月 11 号</a>发布的轻量级 AI Agent 开发框架。<a href="https://www.tizi365.com/openai-agents-sdk/" target="_blank" rel="noopener noreferrer">OpenAI Agents SDK 中文文档</a>。</p><blockquote><p>OpenAI 在 2025 年 3 月 11 号发布的 Responses API，计划在明年全面取代 Assistants API。</p><p><a href="https://github.com/openai/openai-cs-agents-demo" target="_blank" rel="noopener noreferrer">openai-cs-agents-demo</a> 是一个基于 OpenAI Agents SDK 构建的客户服务智能体演示项目，包含 Python 后端智能体编排引擎和 Next.js 前端交互界面。项目完整复现了航空公司客服场景：通过分流智能体（Triage Agent）将用户请求（如改签座位、航班状态查询）自动路由到专业智能体（座位预订/航班状态/FAQ 等模块），并集成了安全护栏机制（防越狱/防无关问题）。用户可通过直观的聊天界面体验多智能体协同处理复杂工作流的全过程，后端采用模块化设计便于自定义提示词和业务逻辑扩展。</p></blockquote><p>Agent SDK 中包括以下三个基本概念：</p><ul><li><!----></li><li><!----></li><li><!----></li></ul><p>在 Agent SDK 的实现中，是基于 Assistants API 来调用配置的 Tools，Tools 可以是 Python 函数，还可以是另外一个 Agent。如果要调用 Tools，就必须使用支持 Assistants API（也就是所谓的“Function Call”）的 LLM。Qwen3 对 Assistants API 支持的非常好，而 DeepSeek-R1 则完全不支持 Assistants API，支持 Assistants API 的是 DeepSeek-V3。DeepSeek-V3 和 DeepSeek-R1 必须结合起来才能开发调用 Tools 的 AI Agent。</p><p>多 Agent 协作的基础就是角色扮演（role playing），角色扮演的基础是在大模型层面，而不是在 AI Agent 开发框架层面，现在主流的大模型都支持角色扮演。</p><p>回到 ADH 项目，AI Agent 的功能通常都特定于具体的需求，因此 AI Agent 应该与通用的 ADH 分隔开。在后端服务器上面创建一个新的 Python 项目，该项目作为一个 Python 库，添加为 ADH 的依赖。这是一种最简单的实现方式，还可以使用 RESTful API 调用的方式。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> init</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 3.10</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> adh-ai-agent</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> adh-ai-agent</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Add agent sdk as a dependency</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> add</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> openai-agents</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># This is the name of the Python package</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">mkdir</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> adh_ai_agent</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>更新 <code>pyproject.toml</code> 文件，使用 <code>setuptools</code> 作为构建系统，把 adh-ai-agent 项目作为一个 Python 库，以便于通过 pip 安装。</p><div class="language-toml line-numbers-mode" data-highlighter="shiki" data-ext="toml" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[[</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">tool</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">index</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]]</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">url</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;https://pypi.tuna.tsinghua.edu.cn/simple&quot;</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">default</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">true</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">build-system</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">requires</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;setuptools&gt;=42&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">build-backend</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;setuptools.build_meta&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>切换到 ADH 项目的根目录。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~/awesome-digital-human-live2d</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>更新 ADH 项目的 <code>pyproject.toml</code> 文件，添加 <code>editable_mode</code> 配置，以便于在开发过程中，自动更新依赖的包。</p><div class="language-toml line-numbers-mode" data-highlighter="shiki" data-ext="toml" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">tool</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">config-settings</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = { </span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">editable_mode</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;compat&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> }</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>添加 <code>adh-ai-agent</code> 作为 ADH 的依赖。这样当依赖项目的代码修改之后，ADH 可以立即使用最新的代码。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -e</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;../adh-ai-agent&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>到这里，一个 AI Agent 项目的初始化工作就完成了。接下来开发一个 ADH agent 类来支持调用上一步创建的外部 AI Agent。<code>digitalHuman/agent/core/repeaterAgent.py</code> 是一个最简单的 ADH Agent 实现，它重复输出用户输入的内容，可以作为模板开发一个新的 ADH Agent <code>digitalHuman/agent/core/outsideAgent.py</code>。</p><blockquote><p>在 <code>run()</code> 函数中，使用 <code>importlib.import_module(AGENT_MODULE)</code> 动态加载外部 AI Agent 的模块，调用了模块的 <code>chat_with_agent()</code> 函数。</p><p>还需要把新创建的 ADH Agent 添加到 <code>digitalHuman/agent/core/__init__.py</code> 文件中。然后在 <code>configs/agents/</code> 目录下创建一个新文件 <code>outsideAgent.yaml</code>，添加新 ADH Agent 的配置。</p><p>最后，在主配置文件 <code>configs/config.yaml</code> 中，把新的 ADH Agent 配置文件名 <code>outsideAgent.yaml</code> 添加到 <code>SERVER.AGENTS.SUPPORT_LIST</code> 列表中。</p></blockquote><h3 id="角色扮演-花木兰" tabindex="-1"><a class="header-anchor" href="#角色扮演-花木兰"><span>角色扮演 - 花木兰</span></a></h3><p>基于 Agent SDK 实现<!---->角色扮演的 AI Agent，对应的代码文件是 <code>adh-ai-agent/adh_ai_agent/mulan.py</code>。准备 <code>.env</code> 文件。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 在 adh-ai-agent 项目根目录下创建 .env 文件</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">cp</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .env.template</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .env</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 在 .env 文件中添加 API_KEY</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">API_KEY</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">your_openai_api_key</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>然后在 ADH 前端设置页面，配置新的 AI 智能体，引擎选择 &quot;OutsideAgent&quot;，引擎配置中 agent_type 设置为默认的 &quot;local_lib&quot;，agent_module 设置为 <code>adh_ai_agent.mulan</code>。</p><h3 id="数字人形象定制" tabindex="-1"><a class="header-anchor" href="#数字人形象定制"><span>数字人形象定制</span></a></h3><p>ADH 前端使用的 2D 数字人，是基于 Live2D 开发的。基于 Live2D 的 2D 数字人模型，可以划分为设计（也就是建模）和应用两个大的环节。</p><ul><li><!---->：使用 Live2D Editor 来进行 2D 数字人的设计。设计的成品会被导出为 Live2D 模型。设计环节的主要工作由设计师来完成。</li><li><!---->：使用 Live2D SDK 将设计环节中导出的 Live2D 模型部署到各种应用之中。应用环节的主要工作由开发者来完成。</li></ul><p><a href="https://docs.live2d.com/zh-CHS/cubism-sdk-tutorials/top/" target="_blank" rel="noopener noreferrer">Live2D SDK 教程</a>。ADH 前端是一个 Web 应用，选择的 SDK 是 <a href="https://docs.live2d.com/zh-CHS/cubism-sdk-tutorials/sample-build-web/" target="_blank" rel="noopener noreferrer">SDK for Web</a>。</p><!----><ol><li>下载和安装 <a href="https://www.live2d.com/zh-CHS/cubism/download/editor/" target="_blank" rel="noopener noreferrer">Live2D Editor</a>。安装好之后，其中有一个工具叫 Live2D Viewer，可以使用这个工具来查看和测试 Live2D Editor 导出的数字人模型。</li><li><a href="https://docs.live2d.com/zh-CHS/cubism-editor-tutorials/top/" target="_blank" rel="noopener noreferrer">Live2D Cubism 教程</a>, <a href="https://docs.live2d.com/zh-CHS/cubism-editor-manual/top/" target="_blank" rel="noopener noreferrer">Live2D Cubism 手册</a>。Live2D 数字人的设计环节，细节非常多，数字人要支持的姿态和动作越多，工作量就越大，也可以考虑去找人购买定制 Live2D 数字人的服务，或者在网上购买现成的 Live2D 数字人模型。<a href="https://www.live2d.com/zh-CHS/learn/sample/" target="_blank" rel="noopener noreferrer">Live2D 官网免费下载使用的模型</a>。此外，B 站是中国 Live2D 设计师 + 开发者的大本营，上面有 Live2D 视频教程和 Live2D 模型，有些模型是免费的，有些是收费的。</li><li>Live2D 数字人模型中包括以下文件(<code>{roleName}</code> 表示数字人角色名): <ul><li><code>{roleName}.model3.json</code>: 模型的配置文件</li><li><code>{roleName}.moc3</code>: 模型的骨骼文件</li><li><code>{roleName}.physics3.json</code>: 物理配置文件</li><li><code>{roleName}.cdi3.json</code>: 自定义参数数据</li><li><code>{roleName}.pose3.json</code>: 姿态配置文件</li><li><code>{roleName}.2048</code>: 这个子目录中是模型的纹理文件，通常是 png 图片</li><li><code>motions</code>: 这个子目录中是各种动作的配置文件，后缀为 <code>.motion3.json</code></li><li><code>expressions</code>: 这个子目录中是各种表情的配置文件，后缀为 <code>.exp3.json</code></li></ul></li></ol><!----><p>以下所有操作是在 ADH 项目根目录下的 <code>web</code> 目录中进行。</p><ol><li><p><a href="https://www.live2d.com/zh-CHS/sdk/about/" target="_blank" rel="noopener noreferrer">Live2D SDK 下载页面</a>选择 <code>SDK for Web</code> 下载。ADH 前端已经集成了 Live2D SDK for Web。</p></li><li><p><code>app/layout.tsx</code> 文件中的 script 标签中，添加 Live2D SDK 的引用（核心 JS 库）。</p></li><li><p><code>public/sentio</code> 目录是 Live2D 数字人模型的相关文件:</p><ul><li><code>characters</code>: 所有的 Live2D 数字人模型的相关文件</li><li><code>backgrounds</code>: 数字人的背景图片</li><li><code>core</code>: 只有一个 <code>live2dcubismcore.min.js</code> 文件，也就是 Live2D SDK 的核心 JS 库</li></ul></li><li><p><code>lib/live2d</code> 目录是 Live2D 相关的库，入口是 <code>live2dManager.js</code>:</p><ul><li><code>changeCharacter</code>: 设置不同的数字人模型</li><li><code>setLipFactor</code>, <code>getLipFactor</code>: 设置数字人的张口幅度参数</li><li>与语音相关的函数: <code>pushAudioQueue</code>, <code>popAudioQueue</code>, <code>clearAudioQueue</code>, <code>playAudio</code>, <code>stopAudio</code>, <code>isAudioPlaying</code></li></ul></li><li><p>在 ADH 前端配置新的自定义数字人模型</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">mkdir</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -p</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> public/sentio/characters/custom/{roleName}</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># copy the Live2D model files to the custom directory</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>在 <code>lib/constants.ts</code> 文件中的 <code>SENTIO_CHARACTER_CUSTOM_MODELS</code> 列表中，添加新的数字人模型名。</p></li><li><p>语音个性化设置，也就是在 ADH 前端 TTS(语音合成) 的设置中，配置新的数字人模型的语音。目前 ADH 后端支持的 TTS 服务有 EdgeTTS, Dify 和<a href="https://cloud.tencent.com/product/tts" target="_blank" rel="noopener noreferrer">腾讯云 TTS</a>(<a href="https://console.cloud.tencent.com/cam/capi" target="_blank" rel="noopener noreferrer">API 密钥管理</a>)。</p></li></ol><p>关于数字人形象定制，目前还在探索阶段。我发现几个非常不错的项目 <a href="https://textoon.org/" target="_blank" rel="noopener noreferrer">Textoon</a>、<a href="https://github.com/evgo2017/vue-live2d" target="_blank" rel="noopener noreferrer">vue-live2d</a> 和 <a href="https://github.com/YiguiDing/vue3-live2d" target="_blank" rel="noopener noreferrer">vue3-live2d</a>，还有这篇知乎文章<a href="https://zhuanlan.zhihu.com/p/12282031509" target="_blank" rel="noopener noreferrer">vue3中实现live2D技术的应用虚拟角色数字人live2d-render、pixi-live2d-display</a>。其中 Textoon 让我印象深刻，可以通过文本描述生成生动的 2D 卡通形象，这是它的 <a href="https://github.com/human3daigc/Textoon" target="_blank" rel="noopener noreferrer">GitHub 仓库</a>。</p><h3 id="rag-agent" tabindex="-1"><a class="header-anchor" href="#rag-agent"><span>RAG Agent</span></a></h3><p>数字人应用场景非常多，比如：客服、导游、在线教育、企业培训、在线法律咨询、在线问诊等。为了实现这些应用场景，需要数字人能够回答用户的问题，必须在 LLM 与现实世界的各种数据源之间建立一个桥梁，让它有能力通过这个桥梁获取外部的信息和知识。</p><p>在排除掉成本很高的 LLM 微调之外，建立 LLM 与外部数据源的桥梁，主要有两种技术手段：</p><ul><li>OpenAI 发布的 <a href="#%E4%BD%BF%E7%94%A8-agent-sdk-%E5%BC%80%E5%8F%91-ai-agent-%E5%AF%B9%E6%8E%A5-adh">Assistants API</a>，也就是 Function Call。</li><li>RAG，这个缩写词的全称是 Retrieval-Augmented Generation，翻译为检索增强生成。</li></ul><p>RAG 比 Assistant API 更复杂，这个思维导图 <a href="https://www.processon.com/preview/676b86e2f80ce653025a271f" target="_blank" rel="noopener noreferrer">RAG Development In Practice</a> 是我在 2025 年一月份整理的。</p><blockquote><p>最近一年一个明显的变化是，越来越多的 RAG 应用开发者开始反思，不再使用以向量数据库为中心的开发方法。OpenAI 是这个趋势的引领者，他们在 2023 年就开始尝试不使用向量数据库。例如这篇技术博客分享了 <a href="https://medium.com/@gaurav21s/rag-without-embeddings-heres-how-openai-is-doing-this-45866cd5ddc6" target="_blank" rel="noopener noreferrer">RAG Without Embeddings? Here&#39;s how OpenAI is doing this…</a>。现在有些开发者也在讨论未来的 LLM 是否可以直接集成 RAG 来解决 LLM 存在的局限，让子弹再飞一会儿。</p></blockquote><p>下面主要介绍 RAG 如何与数字人应用集成，在线客服是一个常见的场景，基于 OpenAI 2025 年新提出来的 RAG 开发方法，来开发 RAG 应用。</p><!----><p>这个 RAG 应用没有使用向量数据库，也没有文本向量化，因为目前的基础 LLM 就可以处理非常大的上下文长度，极大简化了 RAG 的开发流程。向量数据库的开发和维护成本非常高，且需要持续更新和清洗。gpt-4.1 支持的上下文长度是 100 万 tokens, qwen3 满血版支持的上下文长度是 128k tokens。</p><p>新 RAG 应用开发流程可以简化为以下三个步骤：</p><ol><li>将数据源切分成较小的段落。</li><li>根据用户提出的问题，使用 LLM 筛选出与问题最相关的段落。</li><li>把用户提出的问题和上一步筛选出的段落一起发给 LLM，让 LLM 生成回答。</li></ol><p>在后端服务器上的 <code>adh-ai-agent</code> 项目中，添加 RAG 相关的依赖。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> add</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> nltk</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pypdf</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> requests</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> tiktoken</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>预处理 pdf 文件。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># create a .env file in the root directory of the adh-ai-agent project</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># API_KEY=your_openai_api_key</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># data 目录中是预处理后的文件</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> adh_ai_agent/pdf_preprocessor.py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>RAG 应用集成到 ADH 项目中。这个新 AI Agent 的入口是 <code>adh-ai-agent/adh_ai_agent/rag_agent.py</code>。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 在 ADH 后端项目中，重新添加 adh-ai-agent 项目作为依赖，因为 adh-ai-agent 项目中添加了 RAG 相关的依赖</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~/awesome-digital-human-live2d/</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -e</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;../adh-ai-agent&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 创建一个符号链接，以便 ADH 后端能够找到之前预处理保存的 pickle 文件</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">ln</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -s</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ../adh-ai-agent/data</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>启动 ADH 前后端，然后在前端设置页面，配置新的 AI 智能体，引擎选择 &quot;OutsideAgent&quot;，引擎配置中 agent_type 设置为默认的 &quot;local_lib&quot;，agent_module 设置为 <code>adh_ai_agent.rag_agent</code>。</p><p>不过这种新的 RAG 实现方法也有自己的局限：</p><ul><li>必须使用有上下文长度非常大的 LLM。</li><li>把大量数据发给 LLM 处理，处理时间会比较长。如果 RAG 应用对延迟要求非常苛刻，这样的应用难以满足需要。通过实现某种形式的缓存，只能一定程度上缓解这个问题，但是无法彻底解决。</li><li>如果使用第三方提供的 LLM 服务，成本的增加是显而易见的。</li></ul></div><!----><!----><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/JoneyXiao/devopsme/edit/main/src/categories/AI/Digital-Human/Real-time-2D.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">Last Updated:</span><time class="vp-meta-info" datetime="2025-07-03T03:17:24.000Z" data-allow-mismatch>7/3/25, 3:17 AM</time></div><div class="contributors"><span class="vp-meta-label">Contributors: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 87732444@qq.com">Joney Xiao</span><!--]--><!--]--></div></div></footer><!----><div id="comment" class="giscus-wrapper input-top vp-comment" vp-comment style="display:block;"><div style="display: flex;align-items: center;justify-content: center;height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);--icon-size: 48px;display: inline-block;width: var(--icon-size);height: var(--icon-size);background-color: currentcolor;-webkit-mask-image: var(--loading-icon);mask-image: var(--loading-icon)"></span></div></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><!----><div class="vp-copyright">Copyright © 2025 DevOpsMe </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/devopsme/assets/app-D1k-6CWc.js" defer></script>
  </body>
</html>
