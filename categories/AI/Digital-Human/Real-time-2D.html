<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.23" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.88" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Real-time 2D","image":[""],"datePublished":"2025-06-21T18:30:00.000Z","dateModified":"2025-08-22T06:13:40.000Z","author":[{"@type":"Person","name":"DevOpsMe","url":"https://github.com/JoneyXiao/devopsme"}]}</script><meta property="og:url" content="https://vuepress-theme-hope-docs-demo.netlify.app/devopsme/categories/AI/Digital-Human/Real-time-2D.html"><meta property="og:site_name" content="DevOpsMe"><meta property="og:title" content="Real-time 2D"><meta property="og:description" content="LLM 开源社区现有状态，最近没有大新闻，但还是非常活跃，可能大家在埋头骨干研究 AI 原生应用。大家开发 AI 原生应用时，可以参考选择。请以最新数据为准。 带着兴趣和疑问来听这个分享。分享完后，期待能够动手实践。 开源 LM 国内 阿里云 ，多模态 Qwen 2.5 VL, Qwen2.5-Omni , DeepSeek-V3, 多模态目前还未有 ..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2025-08-22T06:13:40.000Z"><meta property="article:tag" content="ai agent"><meta property="article:tag" content="adh"><meta property="article:tag" content="live 2D"><meta property="article:tag" content="real-time-2d"><meta property="article:tag" content="digital-human"><meta property="article:tag" content="ai"><meta property="article:published_time" content="2025-06-21T18:30:00.000Z"><meta property="article:modified_time" content="2025-08-22T06:13:40.000Z"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&family=Lora:ital,wght@0,400..700;1,400..700&display=swap" rel="stylesheet"><link rel="icon" href="/devopsme/favicon.ico"><title>Real-time 2D | DevOpsMe</title><meta name="description" content="LLM 开源社区现有状态，最近没有大新闻，但还是非常活跃，可能大家在埋头骨干研究 AI 原生应用。大家开发 AI 原生应用时，可以参考选择。请以最新数据为准。 带着兴趣和疑问来听这个分享。分享完后，期待能够动手实践。 开源 LM 国内 阿里云 ，多模态 Qwen 2.5 VL, Qwen2.5-Omni , DeepSeek-V3, 多模态目前还未有 ...">
    <link rel="preload" href="/devopsme/assets/style-CIkIPKCI.css" as="style"><link rel="stylesheet" href="/devopsme/assets/style-CIkIPKCI.css">
    <link rel="modulepreload" href="/devopsme/assets/app-D5Np86FI.js"><link rel="modulepreload" href="/devopsme/assets/Real-time-2D.html-BeVcql1r.js"><link rel="modulepreload" href="/devopsme/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/devopsme/assets/index.html-BbXys7wm.js" as="script"><link rel="prefetch" href="/devopsme/assets/portfolio.html-Bm5qGz0G.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-C7SLgYx0.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-DTkNGT5O.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-DCWbQTur.js" as="script"><link rel="prefetch" href="/devopsme/assets/disable.html-DCfQIemR.js" as="script"><link rel="prefetch" href="/devopsme/assets/encrypt.html-qJMNLYXR.js" as="script"><link rel="prefetch" href="/devopsme/assets/layout.html-Bo2COfi0.js" as="script"><link rel="prefetch" href="/devopsme/assets/markdown.html-CU5VgYwS.js" as="script"><link rel="prefetch" href="/devopsme/assets/page.html-BPxxBUID.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-BCqQqooN.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-poHHkUCI.js" as="script"><link rel="prefetch" href="/devopsme/assets/explain-ci-cd.html-UYzquERD.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-B6m8A5qK.js" as="script"><link rel="prefetch" href="/devopsme/assets/cloud-providers.html-D-I2PyhL.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-D5Pxif_a.js" as="script"><link rel="prefetch" href="/devopsme/assets/docker-kubernetes.html-BP8wmyqR.js" as="script"><link rel="prefetch" href="/devopsme/assets/How-to-Ask-Questions-the-Smart-Way.html-Ct_VguY6.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-BYHKdr-O.js" as="script"><link rel="prefetch" href="/devopsme/assets/sre-vs-devops.html-D6vHem75.js" as="script"><link rel="prefetch" href="/devopsme/assets/what-is-devops.html-CoFOJKLI.js" as="script"><link rel="prefetch" href="/devopsme/assets/ansible-advanced.html-D0_LExVs.js" as="script"><link rel="prefetch" href="/devopsme/assets/ansible-basics.html-ZE2y2hmM.js" as="script"><link rel="prefetch" href="/devopsme/assets/ansible-troubleshooting.html-DZIPY2An.js" as="script"><link rel="prefetch" href="/devopsme/assets/infrastructure-as-code.html-C9Iz4dso.js" as="script"><link rel="prefetch" href="/devopsme/assets/observability.html-DWp6e_uK.js" as="script"><link rel="prefetch" href="/devopsme/assets/practical-task.html-ssBfJQ2i.js" as="script"><link rel="prefetch" href="/devopsme/assets/Glossary.html-BYjd9x4e.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-wsyWqcme.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Advanced-Concepts.html-CQbTTd2N.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Architecture.html-5N_53MKw.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Core-Certified-Power-User.html-DmKG3RXn.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Inputs.html-CHGxSjuu.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Installation-Provision.html-BfgQ7sWr.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Searching-Reporting.html-J3CIpOB5.js" as="script"><link rel="prefetch" href="/devopsme/assets/Splunk-Visualizing.html-BJWf_xLC.js" as="script"><link rel="prefetch" href="/devopsme/assets/splunk-interview-questions.html-CyvITx0A.js" as="script"><link rel="prefetch" href="/devopsme/assets/terraform-interview-questions.html-DiCUH0rb.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-CwOsbWtu.js" as="script"><link rel="prefetch" href="/devopsme/assets/baz.html-BRP0p3jv.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-B1Zkg8dG.js" as="script"><link rel="prefetch" href="/devopsme/assets/ray.html-BmLnRnxd.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-xZ2LhB_0.js" as="script"><link rel="prefetch" href="/devopsme/assets/env-setup.html-K6GXlS3Q.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-DXEsvI3r.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-LLdp1LDx.js" as="script"><link rel="prefetch" href="/devopsme/assets/Azure.html-DUZ6udHt.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-C9CxXttm.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-CuiOQKco.js" as="script"><link rel="prefetch" href="/devopsme/assets/docker-interview-questions.html-D9e6HPNG.js" as="script"><link rel="prefetch" href="/devopsme/assets/Closure-and-Decorator.html-BFUO0dXY.js" as="script"><link rel="prefetch" href="/devopsme/assets/AWS-Overview.html-DtzTxA7H.js" as="script"><link rel="prefetch" href="/devopsme/assets/IAM.html-z58fotjg.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-CLn71nvP.js" as="script"><link rel="prefetch" href="/devopsme/assets/404.html-BqHozNe9.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-WlqtI2M9.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-CA5luevb.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-Bd8PgKV_.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-Ct4102lU.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-BHaw5lZj.js" as="script"><link rel="prefetch" href="/devopsme/assets/index.html-BeEV2i3U.js" as="script"><link rel="prefetch" href="/devopsme/assets/photoswipe.esm-DXWKOczD.js" as="script"><link rel="prefetch" href="/devopsme/assets/giscus-1zs_z9NH.js" as="script"><link rel="prefetch" href="/devopsme/assets/index-B-M8YVCw.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/devopsme/" aria-label="Take me home"><img class="vp-nav-logo light" src="/devopsme/assets/image/logos--web-dev-icon-light.svg" alt><img class="vp-nav-logo dark" src="/devopsme/assets/image/logos--web-dev-icon-dark.svg" alt><span class="vp-site-name hide-in-pad">DevOpsMe</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Categories"><!--[--><iconify-icon class="vp-icon" icon="bx:category" height="1em" sizing="height"></iconify-icon>Categories<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Categories</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/cloud/" aria-label="Cloud"><!--[--><iconify-icon class="vp-icon" icon="ic:baseline-cloud" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->Cloud<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/devopsme/categories/AI/" aria-label="AI"><!--[--><iconify-icon class="vp-icon" icon="streamline-flex:ai-chip-robot-remix" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->AI<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/splunk/" aria-label="Splunk"><!--[--><iconify-icon class="vp-icon" icon="ep:arrow-right-bold" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->Splunk<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/general/" aria-label="General"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:universal-access" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->General<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/containers/" aria-label="Containers"><!--[--><iconify-icon class="vp-icon" icon="simple-icons:docker" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->Containers<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/ci-cd/" aria-label="CICD"><!---->CICD<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/infrastructure/" aria-label="Infrastructure"><!---->Infrastructure<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/monitoring/" aria-label="Monitoring"><!---->Monitoring<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/scripting/" aria-label="Scripting"><!---->Scripting<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/devopsme/categories/terraform/" aria-label="Terraform"><!---->Terraform<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/devopsme/portfolio.html" aria-label="About Me"><!--[--><iconify-icon class="vp-icon" icon="qlementine-icons:resume-16" height="1em" sizing="height"></iconify-icon><!--]-->About Me<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/JoneyXiao/devopsme" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:none;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:block;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><div id="docsearch-container" style="display:none;"></div><div><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"><svg width="15" height="15" class="DocSearch-Control-Key-Icon"><path d="M4.505 4.496h2M5.505 5.496v5M8.216 4.496l.055 5.993M10 7.5c.333.333.5.667.5 1v2M12.326 4.5v5.996M8.384 4.496c1.674 0 2.116 0 2.116 1.5s-.442 1.5-2.116 1.5M3.205 9.303c-.09.448-.277 1.21-1.241 1.203C1 10.5.5 9.513.5 8V7c0-1.57.5-2.5 1.464-2.494.964.006 1.134.598 1.24 1.342M12.553 10.5h1.953" stroke-width="1.2" stroke="currentColor" fill="none" stroke-linecap="square"></path></svg></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="vp-icon" icon="fa6-solid:book" width="1em" height="1em" sizing="both"></iconify-icon><span class="vp-sidebar-title">Docs</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="ic:baseline-cloud" width="1em" height="1em" sizing="both"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/devopsme/categories/cloud/" aria-label="Cloud"><!---->Cloud<!----></a><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><iconify-icon class="vp-icon" icon="streamline-flex:ai-chip-robot-remix" width="1em" height="1em" sizing="both"></iconify-icon><a class="route-link route-link-active auto-link vp-sidebar-title no-external-link-icon" href="/devopsme/categories/AI/" aria-label="AI"><!---->AI<!----></a><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/devopsme/categories/AI/Agentic-AI/" aria-label="Agentic AI"><!---->Agentic AI<!----></a><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><a class="route-link route-link-active auto-link vp-sidebar-title no-external-link-icon" href="/devopsme/categories/AI/Digital-Human/" aria-label="Digital Human"><!---->Digital Human<!----></a><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/devopsme/categories/AI/Digital-Human/Real-time-2D.html" aria-label="Real-time 2D"><!---->Real-time 2D<!----></a></li></ul></section></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="ep:arrow-right-bold" width="1em" height="1em" sizing="both"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/devopsme/categories/splunk/" aria-label="Splunk"><!---->Splunk<!----></a><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="fa6-solid:universal-access" width="1em" height="1em" sizing="both"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/devopsme/categories/general/" aria-label="General"><!---->General<!----></a><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><iconify-icon class="vp-icon" icon="simple-icons:docker" width="1em" height="1em" sizing="both"></iconify-icon><a class="route-link auto-link vp-sidebar-title no-external-link-icon" href="/devopsme/categories/containers/" aria-label="Containers"><!---->Containers<!----></a><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">CICD</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Infrastructure</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Monitoring</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Python</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Scripting</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Terraform</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Real-time 2D</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/JoneyXiao/devopsme" target="_blank" rel="noopener noreferrer">DevOpsMe</a></span><span property="author" content="DevOpsMe"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">6/21/25</span><meta property="datePublished" content="2025-06-21T18:30:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 23 min</span><meta property="timeRequired" content="PT23M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color2" role>ai</span><span class="page-category-item color3" role>digital-human</span><!--]--><meta property="articleSection" content="ai,digital-human"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color2" role>ai</span><span class="page-tag-item color3" role>digital-human</span><span class="page-tag-item color4" role>real-time-2d</span><span class="page-tag-item color2" role>live 2D</span><span class="page-tag-item color7" role>adh</span><span class="page-tag-item color6" role>ai agent</span><!--]--><meta property="keywords" content="ai,digital-human,real-time-2d,live 2D,adh,ai agent"></span></div><hr></div><!----><div class="" vp-content><!----><div id="markdown-content"><p>LLM 开源社区现有状态，最近没有大新闻，但还是非常活跃，可能大家在埋头骨干研究 AI 原生应用。大家开发 AI 原生应用时，可以参考选择。请以最新数据为准。</p><p>带着兴趣和疑问来听这个分享。分享完后，期待能够动手实践。</p><h2 id="开源-lm" tabindex="-1"><a class="header-anchor" href="#开源-lm"><span>开源 LM</span></a></h2><h3 id="国内" tabindex="-1"><a class="header-anchor" href="#国内"><span>国内</span></a></h3><ul><li>阿里云 <!---->，多模态 Qwen 2.5 VL, Qwen2.5-Omni</li><li><!---->, DeepSeek-V3, 多模态目前还未有</li><li>智谱 AI GLM-4，多模态 VisualGLM-6B, CogVLM-17B</li><li>腾讯云 Hunyuan-MoE-A52B，多模态 Hunyuan-DiT，Hunyuan3D 2.0</li></ul><h3 id="国外" tabindex="-1"><a class="header-anchor" href="#国外"><span>国外</span></a></h3><ul><li>Meta Llama4, 多模态 Llama4, Llama 4 Scout, Llama 4 Maverick</li><li>Mistral Small 3.1, 多模态 Mistral Small 3.1</li><li>Google Gemma3, 多模态 Gemma3</li><li>xAI Grok-1, Grok-2, 多模态目前还未有</li></ul><h2 id="开源-lm-发布平台" tabindex="-1"><a class="header-anchor" href="#开源-lm-发布平台"><span>开源 LM 发布平台</span></a></h2><ul><li><a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">Hugging Face Hub</a></li><li><a href="https://www.modelscope.cn/models" target="_blank" rel="noopener noreferrer">ModelScope</a></li><li><a href="https://ollama.com/search" target="_blank" rel="noopener noreferrer">Ollama</a></li></ul><h2 id="开源-lm-部署工具" tabindex="-1"><a class="header-anchor" href="#开源-lm-部署工具"><span>开源 LM 部署工具</span></a></h2><table><thead><tr><th style="text-align:left;">主流 LM 部署工具</th><th style="text-align:left;">其它 LM 部署工具</th></tr></thead><tbody><tr><td style="text-align:left;">- <a href="https://github.com/ollama/ollama" target="_blank" rel="noopener noreferrer">Ollama</a></td><td style="text-align:left;">- <a href="https://github.com/ggml-org/llama.cpp" target="_blank" rel="noopener noreferrer">llama.cpp</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer">vLLM</a></td><td style="text-align:left;">- <a href="https://github.com/Mozilla-Ocho/llamafile" target="_blank" rel="noopener noreferrer">llamafile</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">Hugging Face Transformers</a></td><td style="text-align:left;">- <a href="https://github.com/nomic-ai/gpt4all" target="_blank" rel="noopener noreferrer">GPT4All</a></td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;">- <a href="https://github.com/sgl-project/sglang" target="_blank" rel="noopener noreferrer">SGLang</a></td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;">- <a href="https://github.com/mlc-ai/web-llm" target="_blank" rel="noopener noreferrer">WebLLM</a></td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;">- <a href="https://github.com/ModelTC/lightllm" target="_blank" rel="noopener noreferrer">LightLLM</a></td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;">- <a href="https://github.com/microsoft/BitNet" target="_blank" rel="noopener noreferrer">BitNet</a></td></tr></tbody></table><h2 id="开源-ai-agent-开发框架" tabindex="-1"><a class="header-anchor" href="#开源-ai-agent-开发框架"><span>开源 AI Agent 开发框架</span></a></h2><blockquote><p>2024 年 AI Agent 开发领域以开源社区为主，2025 年大厂开始发力，在我看来，AI Agent 开发框架会以开源社区为主。<br><a href="https://learn.microsoft.com/en-us/azure/ai-foundry/agents/overview" target="_blank" rel="noopener noreferrer">Azure AI Foundry Agent Service</a> 是一个将模型、工具、框架和治理机制整合为统一平台的系统，用于构建智能体。</p></blockquote><table><thead><tr><th style="text-align:left;">通⽤ AI Agent 开发框架</th><th style="text-align:left;">RAG 开发框架</th><th style="text-align:left;">低代码开发⼯具</th><th style="text-align:left;">类 Manus 开发框架</th></tr></thead><tbody><tr><td style="text-align:left;">- <a href="https://github.com/langchain-ai/langgraph" target="_blank" rel="noopener noreferrer">LangChain + LangGraph</a></td><td style="text-align:left;">- <a href="https://github.com/run-llama/llama_index" target="_blank" rel="noopener noreferrer">LlamaIndex</a></td><td style="text-align:left;">- <a href="https://github.com/langgenius/dify" target="_blank" rel="noopener noreferrer">Dify</a></td><td style="text-align:left;">- <a href="https://github.com/FoundationAgents/OpenManus" target="_blank" rel="noopener noreferrer">OpenManus</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/crewAIInc/crewAI" target="_blank" rel="noopener noreferrer">CrewAI</a></td><td style="text-align:left;">- <a href="https://github.com/microsoft/graphrag" target="_blank" rel="noopener noreferrer">GraphRAG</a></td><td style="text-align:left;">- <a href="https://github.com/labring/FastGPT" target="_blank" rel="noopener noreferrer">FastGPT</a></td><td style="text-align:left;">- <a href="https://github.com/camel-ai/owl" target="_blank" rel="noopener noreferrer">OWL</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/openai/openai-agents-python" target="_blank" rel="noopener noreferrer">Agent SDK</a></td><td style="text-align:left;">- <a href="https://github.com/chatchat-space/Langchain-Chatchat" target="_blank" rel="noopener noreferrer">LangChain-Chatchat</a></td><td style="text-align:left;">- <a href="https://github.com/FlowiseAI/Flowise" target="_blank" rel="noopener noreferrer">Flowise</a></td><td style="text-align:left;">- <a href="https://github.com/femto/minion-agent" target="_blank" rel="noopener noreferrer">Minion-Agent</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/Significant-Gravitas/AutoGPT" target="_blank" rel="noopener noreferrer">AutoGPT Platform</a></td><td style="text-align:left;"></td><td style="text-align:left;">- <a href="https://github.com/n8n-io/n8n" target="_blank" rel="noopener noreferrer">n8n</a></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/microsoft/autogen" target="_blank" rel="noopener noreferrer">AutoGen</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/FoundationAgents/MetaGPT" target="_blank" rel="noopener noreferrer">MetaGPT</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/camel-ai/camel" target="_blank" rel="noopener noreferrer">Camel</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/yoheinakajima/babyagi" target="_blank" rel="noopener noreferrer">BabyAGI</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/Link-AGI/AutoAgents" target="_blank" rel="noopener noreferrer">AutoAgents</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://google.github.io/adk-docs/" target="_blank" rel="noopener noreferrer">Google- ADK</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://strandsagents.com/latest/" target="_blank" rel="noopener noreferrer">AWS - Strands Agents</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr></tbody></table><h2 id="开源数字人项目" tabindex="-1"><a class="header-anchor" href="#开源数字人项目"><span>开源数字人项目</span></a></h2><table><thead><tr><th style="text-align:left;">⾮实时数字⼈</th><th style="text-align:left;">2D 实时数字人</th><th style="text-align:left;">3D 实时数字人</th></tr></thead><tbody><tr><td style="text-align:left;">- <a href="https://github.com/antgroup/echomimic_v2" target="_blank" rel="noopener noreferrer">EchoMimic V2</a></td><td style="text-align:left;">- <a href="https://github.com/wan-h/awesome-digital-human-live2d" target="_blank" rel="noopener noreferrer">ADH</a></td><td style="text-align:left;">- <a href="https://github.com/HumanAIGC-Engineering/OpenAvatarChat" target="_blank" rel="noopener noreferrer">阿里达摩院 OpenAvatarChat</a><br><a href="https://www.openavatarchat.ai/playground" target="_blank" rel="noopener noreferrer">Playground</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/duixcom/Duix.Heygem" target="_blank" rel="noopener noreferrer">Heygem</a></td><td style="text-align:left;">- <a href="https://github.com/lipku/livetalking" target="_blank" rel="noopener noreferrer">LiveTalking</a></td><td style="text-align:left;">- <a href="https://github.com/Henry-23/VideoChat" target="_blank" rel="noopener noreferrer">VideoChat</a></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/jixiaozhong/Sonic" target="_blank" rel="noopener noreferrer">Sonic</a></td><td style="text-align:left;">- <a href="https://github.com/anliyuan/Ultralight-Digital-Human" target="_blank" rel="noopener noreferrer">Ultralight-Digital-Human</a><br>(2.5D - AI 模型实时生成)</td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/KwaiVGI/LivePortrait" target="_blank" rel="noopener noreferrer">LivePortrait</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/xszyou/fay" target="_blank" rel="noopener noreferrer">Fay</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/OpenTalker/SadTalker" target="_blank" rel="noopener noreferrer">SadTalker</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/bytedance/LatentSync" target="_blank" rel="noopener noreferrer">LatentSync</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr><tr><td style="text-align:left;">- <a href="https://github.com/JOY-MM/JoyGen" target="_blank" rel="noopener noreferrer">JoyGen</a></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr></tbody></table><h2 id="商业-3d-数字人" tabindex="-1"><a class="header-anchor" href="#商业-3d-数字人"><span>商业 3D 数字人</span></a></h2><ul><li><p><a href="https://blogs.nvidia.cn/blog/digital-humans-ace-generative-ai-microservices/" target="_blank" rel="noopener noreferrer">Nvidia ACE</a></p><!----> 是目前最为逼真的数字人服务，支持实时交互。当然，价格不菲。视频中展示了非常多的应用场景，还有 <a href="https://build.nvidia.com/nvidia/digital-humans-for-customer-service" target="_blank" rel="noopener noreferrer">在线 demo</a> 可以体验。<p><a href="https://www.bilibili.com/video/BV1Dz42187yB/" target="_blank" rel="noopener noreferrer">B 站上更完整的 Nvidia 数字人演示视频</a></p><!--[--><div class="bilibili-desc"><a class="sr-only" href="https://player.bilibili.com/player.html?bvid=BV1Dz42187yB&amp;t=0&amp;autoplay=0">A BiliBili video</a></div><iframe src="https://player.bilibili.com/player.html?bvid=BV1Dz42187yB&amp;t=0&amp;autoplay=0" title="A BiliBili video" class="bilibili-iframe" allow="accelerometer; autoplay; clipboard-write; encrypted-media; fullscreen; gyroscope; picture-in-picture" style="width:100%;height:0;"></iframe><div style="display: flex;align-items: center;justify-content: center;height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);--icon-size: 48px;display: inline-block;width: var(--icon-size);height: var(--icon-size);background-color: currentcolor;-webkit-mask-image: var(--loading-icon);mask-image: var(--loading-icon)"></span></div><!--]--></li><li><p><a href="https://www.metahuman.com/en-US" target="_blank" rel="noopener noreferrer">Metahuman</a>。创建并驱动完全定制的高度逼真 3D 数字人。</p></li></ul><h2 id="adh-2d-实时数字人" tabindex="-1"><a class="header-anchor" href="#adh-2d-实时数字人"><span><!----></span></a></h2><p>开源项目 <a href="https://github.com/wan-h/awesome-digital-human-live2d" target="_blank" rel="noopener noreferrer">awesome-digital-human-live2d</a>，缩写为 ADH，是国内优秀开发者<!---->老师在 2024 年开发的。ADH 项目分成后端和前端两部分。<!---->。可以本地部署开源大模型，也可以使用<a href="https://bailian.console.aliyun.com/?tab=model#/model-market" target="_blank" rel="noopener noreferrer">阿里云百炼模型广场</a>。</p><figure><img src="/devopsme/assets/adh-arch-high-level-DbnZJ3XR.png" alt="ADH 架构" tabindex="0" loading="lazy"><figcaption>ADH 架构</figcaption></figure><h3 id="部署-adh-前后端" tabindex="-1"><a class="header-anchor" href="#部署-adh-前后端"><span>部署 ADH 前后端</span></a></h3><!----><p>ADH 后端就是一个基于 FastAPI 开发的服务，它的主要作用是集成外部的一些基础服务（包括 ASR、TTS、LLM 三类）和外部的 AI Agent，暴露 RESTful API 给前端使用。ADH 前端遵循 BFF 架构模式（Backend for Frontend），而支持 BFF 架构前端的理想选择就是微服务，主要是基于 RESTful API 的微服务。而使用 Python 开发微服务的首选开发框架就是 FastAPI。</p><p>ADH 后端按照目录结构呈现微单向依赖关系，代码采用标准的 OOP 面向对象风格编写。</p><figure><img src="/devopsme/assets/adh-backend-depends-uA9GwTy2.png" alt="ADH 后端目录结构单向依赖关系" tabindex="0" loading="lazy"><figcaption>ADH 后端目录结构单向依赖关系</figcaption></figure><p>ADH 后端部署的步骤：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Python 3.10 on 22.04 and Python 3.12 on 24.04 by default</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> apt</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python3</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python3-pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python3-dev</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">curl</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -LsSf</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://astral.sh/uv/install.sh</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> | </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sh</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># FFmpeg</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> apt</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> update</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> apt</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ffmpeg</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Clone ADH, ADH official repo is https://github.com/wan-h/awesome-digital-human-live2d.git</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># This repo is a fork of the official repo, with some modifications.</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> clone</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/freecoinx/awesome-digital-human-live2d.git</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> awesome-digital-human-live2d</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Init a uv project</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> init</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 3.10</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Update `pyproject.toml` to use Tsinghua University&#39;s PyPI mirror</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Add the following section at the beginning of the file:</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># [[tool.uv.index]]</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># url = &quot;https://pypi.tuna.tsinghua.edu.cn/simple&quot;</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># default = true</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Install dependencies</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> add</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> $(</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">cat</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> requirements.txt</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Create the main config file (port: 8002)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> configs</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">cp</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> config_template.yaml</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> config.yaml</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Run the ADH backend server</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~/awesome-digital-human-live2d</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> main.py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><!----><p>ADH 前端是一个标准的 H5 页面，而且支持被内嵌在其他 H5 页面中，例如微信小程序。Next.js 应用的架构遵循标准的 BFF（Backend for Frontend）架构模式。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Install Node.js(v22.16.0) https://nodejs.org/en/download</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">npm</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -g</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> next</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">npm</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -g</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> heroui-cli</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">corepack</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> enable</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pnpm</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Clone ADH, ADH official repo is https://github.com/wan-h/awesome-digital-human-live2d.git</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># This repo is a fork of the official repo, with some modifications.</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> clone</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/freecoinx/awesome-digital-human-live2d.git</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> awesome-digital-human-live2d/web</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Install dependencies</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pnpm</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Update frontend configs</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># NEXT_PUBLIC_SERVER_IP=&quot;&lt;ADH backend server IP&gt;&quot;</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># NEXT_PUBLIC_SERVER_PORT=&quot;&lt;ADH backend server port&gt;&quot;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">copy</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .env_template</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .env</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Run the ADH frontend server</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pnpm</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> build</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pnpm</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> start</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><!----><p>在 UI 设置界面配置 AI Agent，引擎选择 &quot;OpenAI&quot;，引擎配置我用的是阿里云百炼模型广场的 <code>qwen3-8b</code>，TTS 默认使用的免费服务是 <a href="https://edge-tts.com/" target="_blank" rel="noopener noreferrer">EdgeTTS</a>。</p><figure><img src="/devopsme/assets/adh-ui-Capo3slK.png" alt="ADH UI" tabindex="0" loading="lazy"><figcaption>ADH UI</figcaption></figure><h3 id="使用-agent-sdk-开发-ai-agent-对接-adh" tabindex="-1"><a class="header-anchor" href="#使用-agent-sdk-开发-ai-agent-对接-adh"><span>使用 Agent SDK 开发 AI Agent 对接 ADH</span></a></h3><p>目前 ADH 后端已经实现了与 Dify、FastGPT 开发的 AI Agent 的对接。我们将实现与 Agent SDK 开发的 AI Agent 的对接。下文提到的外部 AI Agent 的代码文件在 GitHub 仓库 <a href="https://github.com/JoneyXiao/adh-ai-agent" target="_blank" rel="noopener noreferrer">adh-ai-agent</a> 中。</p><p><a href="https://openai.github.io/openai-agents-python/" target="_blank" rel="noopener noreferrer">Agent SDK</a> 是 OpenAI 在 <a href="https://openai.com/index/new-tools-for-building-agents/" target="_blank" rel="noopener noreferrer">2025 年 3 月 11 号</a>发布的轻量级 AI Agent 开发框架。<a href="https://www.tizi365.com/openai-agents-sdk/" target="_blank" rel="noopener noreferrer">OpenAI Agents SDK 中文文档</a>。</p><blockquote><p>OpenAI 在 2025 年 3 月 11 号发布的 Responses API，计划在明年全面取代 Assistants API。</p><p><a href="https://github.com/openai/openai-cs-agents-demo" target="_blank" rel="noopener noreferrer">openai-cs-agents-demo</a> 是一个基于 OpenAI Agents SDK 构建的客户服务智能体演示项目，包含 Python 后端智能体编排引擎和 Next.js 前端交互界面。项目完整复现了航空公司客服场景：通过分流智能体（Triage Agent）将用户请求（如改签座位、航班状态查询）自动路由到专业智能体（座位预订/航班状态/FAQ 等模块），并集成了安全护栏机制（防越狱/防无关问题）。用户可通过直观的聊天界面体验多智能体协同处理复杂工作流的全过程，后端采用模块化设计便于自定义提示词和业务逻辑扩展。</p></blockquote><p>Agent SDK 中包括以下四个基本概念：</p><ul><li><!----></li><li><!----></li><li><!----></li><li><!----></li></ul><p>在 Agent SDK 的实现中，是基于 Assistants API 来调用配置的 Tools，Tools 可以是 Python 函数，还可以是另外一个 Agent。如果要调用 Tools，就必须使用支持 Assistants API（也就是所谓的“Function Call”）的 LLM。Qwen3 对 Assistants API 支持的非常好，而 DeepSeek-R1 则完全不支持 Assistants API，支持 Assistants API 的是 DeepSeek-V3。DeepSeek-V3 和 DeepSeek-R1 必须结合起来才能开发调用 Tools 的 AI Agent。</p><p>多 Agent 协作的基础就是角色扮演（role playing），角色扮演的基础是在大模型层面，而不是在 AI Agent 开发框架层面，现在主流的大模型都支持角色扮演。</p><p>回到 ADH 项目，AI Agent 的功能通常都特定于具体的需求，因此 AI Agent 应该与通用的 ADH 分隔开。在后端服务器上面创建一个新的 Python 项目，该项目作为一个 Python 库，添加为 ADH 的依赖。这是一种最简单的实现方式，还可以使用 RESTful API 调用的方式。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> init</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 3.10</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> adh-ai-agent</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> adh-ai-agent</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Add agent sdk as a dependency</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> add</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> openai-agents</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># This is the name of the Python package</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">mkdir</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> adh_ai_agent</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>更新 <code>pyproject.toml</code> 文件，使用 <code>setuptools</code> 作为构建系统，把 adh-ai-agent 项目作为一个 Python 库，以便于通过 pip 安装。</p><div class="language-toml line-numbers-mode" data-highlighter="shiki" data-ext="toml" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[[</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">tool</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">index</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]]</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">url</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;https://pypi.tuna.tsinghua.edu.cn/simple&quot;</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">default</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">true</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">build-system</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">requires</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;setuptools&gt;=42&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">build-backend</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;setuptools.build_meta&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>切换到 ADH 项目的根目录。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~/awesome-digital-human-live2d</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>更新 ADH 项目的 <code>pyproject.toml</code> 文件，添加 <code>editable_mode</code> 配置，以便于在开发过程中，自动更新依赖的包。</p><div class="language-toml line-numbers-mode" data-highlighter="shiki" data-ext="toml" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">tool</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">config-settings</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = { </span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">editable_mode</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;compat&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> }</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>添加 <code>adh-ai-agent</code> 作为 ADH 的依赖。这样当依赖项目的代码修改之后，ADH 可以立即使用最新的代码。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -e</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;../adh-ai-agent&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>到这里，一个 AI Agent 项目的初始化工作就完成了。接下来开发一个 ADH agent 类来支持调用上一步创建的外部 AI Agent。<code>digitalHuman/agent/core/repeaterAgent.py</code> 是一个最简单的 ADH Agent 实现，它重复输出用户输入的内容，可以作为模板开发一个新的 ADH Agent <code>digitalHuman/agent/core/outsideAgent.py</code>。</p><blockquote><p>在 <code>run()</code> 函数中，使用 <code>importlib.import_module(AGENT_MODULE)</code> 动态加载外部 AI Agent 的模块，调用了模块的 <code>chat_with_agent()</code> 函数。</p><p>还需要把新创建的 ADH Agent 添加到 <code>digitalHuman/agent/core/__init__.py</code> 文件中。然后在 <code>configs/agents/</code> 目录下创建一个新文件 <code>outsideAgent.yaml</code>，添加新 ADH Agent 的配置。</p><p>最后，在主配置文件 <code>configs/config.yaml</code> 中，把新的 ADH Agent 配置文件名 <code>outsideAgent.yaml</code> 添加到 <code>SERVER.AGENTS.SUPPORT_LIST</code> 列表中。</p></blockquote><h3 id="角色扮演-花木兰" tabindex="-1"><a class="header-anchor" href="#角色扮演-花木兰"><span>角色扮演 - 花木兰</span></a></h3><p>基于 Agent SDK 实现<!---->角色扮演的 AI Agent，对应的代码文件是 <code>adh-ai-agent/adh_ai_agent/mulan.py</code>。准备 <code>.env</code> 文件。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 在 adh-ai-agent 项目根目录下创建 .env 文件</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">cp</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .env.template</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .env</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 在 .env 文件中添加 API_KEY</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">API_KEY</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">your_openai_api_key</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>然后在 ADH 前端设置页面，配置新的 AI 智能体，引擎选择 &quot;OutsideAgent&quot;，引擎配置中 agent_type 设置为默认的 &quot;local_lib&quot;，agent_module 设置为 <code>adh_ai_agent.mulan</code>。</p><p>我准备了三个问题来测试花木兰 AI Agent 的回答。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>1. 看到征兵文书时，你决定代替年老体弱的父亲上战场，难道不怕战死沙场吗？</span></span>
<span class="line"><span>2. 当你在窗前梳起长发时，可曾遗憾错过十二年青春？</span></span>
<span class="line"><span>3. 你已经十二年没有见到你的家人了，你最想见到谁？</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="数字人形象定制" tabindex="-1"><a class="header-anchor" href="#数字人形象定制"><span>数字人形象定制</span></a></h3><p>ADH 前端使用的 2D 数字人，是基于 Live2D 开发的。基于 Live2D 的 2D 数字人模型，可以划分为设计（也就是建模）和应用两个大的环节。</p><ul><li><!---->：使用 Live2D Editor 来进行 2D 数字人的设计。设计的成品会被导出为 Live2D 模型。设计环节的主要工作由设计师来完成。</li><li><!---->：使用 Live2D SDK 将设计环节中导出的 Live2D 模型部署到各种应用之中。应用环节的主要工作由开发者来完成。</li></ul><p><a href="https://docs.live2d.com/zh-CHS/cubism-sdk-tutorials/top/" target="_blank" rel="noopener noreferrer">Live2D SDK 教程</a>。ADH 前端是一个 Web 应用，选择的 SDK 是 <a href="https://docs.live2d.com/zh-CHS/cubism-sdk-tutorials/sample-build-web/" target="_blank" rel="noopener noreferrer">SDK for Web</a>。</p><!----><ol><li>下载和安装 <a href="https://www.live2d.com/zh-CHS/cubism/download/editor/" target="_blank" rel="noopener noreferrer">Live2D Editor</a>。安装好之后，其中有一个工具叫 Live2D Viewer，可以使用这个工具来查看和测试 Live2D Editor 导出的数字人模型。</li><li><a href="https://docs.live2d.com/zh-CHS/cubism-editor-tutorials/top/" target="_blank" rel="noopener noreferrer">Live2D Cubism 教程</a>, <a href="https://docs.live2d.com/zh-CHS/cubism-editor-manual/top/" target="_blank" rel="noopener noreferrer">Live2D Cubism 手册</a>。Live2D 数字人的设计环节，细节非常多，数字人要支持的姿态和动作越多，工作量就越大，也可以考虑去找人购买定制 Live2D 数字人的服务，或者在网上购买现成的 Live2D 数字人模型。<a href="https://www.live2d.com/zh-CHS/learn/sample/" target="_blank" rel="noopener noreferrer">Live2D 官网免费下载使用的模型</a>。此外，B 站是中国 Live2D 设计师 + 开发者的大本营，上面有 Live2D 视频教程和 Live2D 模型，有些模型是免费的，有些是收费的。</li><li>Live2D 数字人模型中包括以下文件(<code>{roleName}</code> 表示数字人角色名): <ul><li><code>{roleName}.model3.json</code>: 模型的配置文件</li><li><code>{roleName}.moc3</code>: 模型的骨骼文件</li><li><code>{roleName}.physics3.json</code>: 物理配置文件</li><li><code>{roleName}.cdi3.json</code>: 自定义参数数据</li><li><code>{roleName}.pose3.json</code>: 姿态配置文件</li><li><code>{roleName}.2048</code>: 这个子目录中是模型的纹理文件，通常是 png 图片</li><li><code>motions</code>: 这个子目录中是各种动作的配置文件，后缀为 <code>.motion3.json</code></li><li><code>expressions</code>: 这个子目录中是各种表情的配置文件，后缀为 <code>.exp3.json</code></li></ul></li></ol><!----><p>以下所有操作是在 ADH 项目根目录下的 <code>web</code> 目录中进行。</p><ol><li><p><a href="https://www.live2d.com/zh-CHS/sdk/about/" target="_blank" rel="noopener noreferrer">Live2D SDK 下载页面</a>选择 <code>SDK for Web</code> 下载。ADH 前端已经集成了 Live2D SDK for Web。</p></li><li><p><code>app/layout.tsx</code> 文件中的 script 标签中，添加 Live2D SDK 的引用（核心 JS 库）。</p></li><li><p><code>public/sentio</code> 目录是 Live2D 数字人模型的相关文件:</p><ul><li><code>characters</code>: 所有的 Live2D 数字人模型的相关文件</li><li><code>backgrounds</code>: 数字人的背景图片</li><li><code>core</code>: 只有一个 <code>live2dcubismcore.min.js</code> 文件，也就是 Live2D SDK 的核心 JS 库</li></ul></li><li><p><code>lib/live2d</code> 目录是 Live2D 相关的库，入口是 <code>live2dManager.js</code>:</p><ul><li><code>changeCharacter</code>: 设置不同的数字人模型</li><li><code>setLipFactor</code>, <code>getLipFactor</code>: 设置数字人的张口幅度参数</li><li>与语音相关的函数: <code>pushAudioQueue</code>, <code>popAudioQueue</code>, <code>clearAudioQueue</code>, <code>playAudio</code>, <code>stopAudio</code>, <code>isAudioPlaying</code></li></ul></li><li><p>在 ADH 前端配置新的自定义数字人模型</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">mkdir</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -p</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> public/sentio/characters/custom/{roleName}</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># copy the Live2D model files to the custom directory</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>在 <code>lib/constants.ts</code> 文件中的 <code>SENTIO_CHARACTER_CUSTOM_MODELS</code> 列表中，添加新的数字人模型名。</p></li><li><p>语音个性化设置，也就是在 ADH 前端 TTS(语音合成) 的设置中，配置新的数字人模型的语音。目前 ADH 后端支持的 TTS 服务有 EdgeTTS, Dify 和<a href="https://cloud.tencent.com/product/tts" target="_blank" rel="noopener noreferrer">腾讯云 TTS</a>(<a href="https://console.cloud.tencent.com/cam/capi" target="_blank" rel="noopener noreferrer">API 密钥管理</a>)。</p></li></ol><p>关于数字人形象定制，目前还在探索阶段。我发现几个非常不错的项目 <a href="https://textoon.org/" target="_blank" rel="noopener noreferrer">Textoon</a>、<a href="https://github.com/evgo2017/vue-live2d" target="_blank" rel="noopener noreferrer">vue-live2d</a> 和 <a href="https://github.com/YiguiDing/vue3-live2d" target="_blank" rel="noopener noreferrer">vue3-live2d</a>，还有这篇知乎文章<a href="https://zhuanlan.zhihu.com/p/12282031509" target="_blank" rel="noopener noreferrer">vue3中实现live2D技术的应用虚拟角色数字人live2d-render、pixi-live2d-display</a>。其中 Textoon 让我印象深刻，可以通过文本描述生成生动的 2D 卡通形象，这是它的 <a href="https://github.com/human3daigc/Textoon" target="_blank" rel="noopener noreferrer">GitHub 仓库</a>。</p><h3 id="rag-agent" tabindex="-1"><a class="header-anchor" href="#rag-agent"><span>RAG Agent</span></a></h3><p>数字人应用场景非常多，比如：客服、导游、在线教育、企业培训、在线法律咨询、在线问诊等。为了实现这些应用场景，需要数字人能够回答用户的问题，必须在 LLM 与现实世界的各种数据源之间建立一个桥梁，让它有能力通过这个桥梁获取外部的信息和知识。</p><p>在排除掉成本很高的 LLM 微调之外，建立 LLM 与外部数据源的桥梁，主要有两种技术手段：</p><ul><li>OpenAI 发布的 <a href="#%E4%BD%BF%E7%94%A8-agent-sdk-%E5%BC%80%E5%8F%91-ai-agent-%E5%AF%B9%E6%8E%A5-adh">Assistants API</a>，也就是 Function Call。</li><li>RAG，这个缩写词的全称是 Retrieval-Augmented Generation，翻译为检索增强生成。</li></ul><p>RAG 比 Assistant API 更复杂，这个思维导图 <a href="https://www.processon.com/preview/676b86e2f80ce653025a271f" target="_blank" rel="noopener noreferrer">RAG Development In Practice</a> 是我在 2025 年一月份整理的。</p><blockquote><p>最近一年一个明显的变化是，越来越多的 RAG 应用开发者开始反思，不再使用以向量数据库为中心的开发方法。OpenAI 是这个趋势的引领者，他们在 2023 年就开始尝试不使用向量数据库。例如这篇技术博客分享了 <a href="https://medium.com/@gaurav21s/rag-without-embeddings-heres-how-openai-is-doing-this-45866cd5ddc6" target="_blank" rel="noopener noreferrer">RAG Without Embeddings? Here&#39;s how OpenAI is doing this…</a>。现在有些开发者也在讨论未来的 LLM 是否可以直接集成 RAG 来解决 LLM 存在的局限，让子弹再飞一会儿。</p></blockquote><p>下面主要介绍 RAG 如何与数字人应用集成，在线客服是一个常见的场景，基于 OpenAI 2025 年新提出来的 RAG 开发方法，来开发 RAG 应用。</p><!----><p>这个 RAG 应用没有使用向量数据库，也没有文本向量化，因为目前的基础 LLM 就可以处理非常大的上下文长度，极大简化了 RAG 的开发流程。向量数据库的开发和维护成本非常高，且需要持续更新和清洗。gpt-4.1 支持的上下文长度是 100 万 tokens, qwen3 满血版支持的上下文长度是 128k tokens。</p><p>新 RAG 应用开发流程可以简化为以下三个步骤：</p><ol><li>将数据源切分成较小的段落。</li><li>根据用户提出的问题，使用 LLM 筛选出与问题最相关的段落。</li><li>把用户提出的问题和上一步筛选出的段落一起发给 LLM，让 LLM 生成回答。</li></ol><p>在后端服务器上的 <code>adh-ai-agent</code> 项目中，添加 RAG 相关的依赖。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> add</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> nltk</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pypdf</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> requests</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> tiktoken</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>预处理 pdf 文件。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># create a .env file in the root directory of the adh-ai-agent project</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># API_KEY=your_openai_api_key</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># data 目录中是预处理后的文件</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> adh_ai_agent/pdf_preprocessor.py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>RAG 应用集成到 ADH 项目中。这个新 AI Agent 的入口是 <code>adh-ai-agent/adh_ai_agent/rag_agent.py</code>。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 在 ADH 后端项目中，重新添加 adh-ai-agent 项目作为依赖，因为 adh-ai-agent 项目中添加了 RAG 相关的依赖</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~/awesome-digital-human-live2d/</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -e</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;../adh-ai-agent&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 创建一个符号链接，以便 ADH 后端能够找到之前预处理保存的 pickle 文件</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">ln</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -s</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ../adh-ai-agent/data</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> .</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>启动 ADH 前后端，然后在前端设置页面，配置新的 AI 智能体，引擎选择 &quot;OutsideAgent&quot;，引擎配置中 agent_type 设置为默认的 &quot;local_lib&quot;，agent_module 设置为 <code>adh_ai_agent.rag_agent</code>。</p><p>不过这种新的 RAG 实现方法也有自己的局限：</p><ul><li>必须使用有上下文长度非常大的 LLM。</li><li>把大量数据发给 LLM 处理，处理时间会比较长。如果 RAG 应用对延迟要求非常苛刻，这样的应用难以满足需要。通过实现某种形式的缓存，只能一定程度上缓解这个问题，但是无法彻底解决。</li><li>如果使用第三方提供的 LLM 服务，成本的增加是显而易见的。</li></ul><!----><p>流行的嵌入模型和向量数据库介绍</p><table><thead><tr><th>类别</th><th>类型</th><th>产品/模型</th><th>详细描述</th></tr></thead><tbody><tr><td><strong>嵌入模型</strong></td><td>商业版</td><td>text-embedding-3-small</td><td>OpenAI 提供的嵌入模型，课程中测试使用</td></tr><tr><td></td><td></td><td>Google、阿里云、腾讯云、智谱 AI</td><td>基础 LLM 厂商都有自己的嵌入模型</td></tr><tr><td></td><td>开源</td><td>nomic-embed-text</td><td>可以通过 Ollama 来部署和使用</td></tr><tr><td></td><td></td><td>bge-large</td><td>可以通过 Ollama 来部署和使用</td></tr><tr><td></td><td></td><td>bge-m3</td><td>可以通过 Ollama 来部署和使用</td></tr><tr><td><strong>向量数据库</strong></td><td>商业版</td><td>OpenAI 官方推荐</td><td><a href="https://cookbook.openai.com/examples/vector_databases/readme" target="_blank" rel="noopener noreferrer">Vector databases</a></td></tr><tr><td></td><td></td><td>阿里云、腾讯云</td><td>国内云平台厂商的向量数据库产品</td></tr><tr><td></td><td></td><td>Chroma、Milvus、Weaviate</td><td>专业厂商，既有商业版也有开源版</td></tr><tr><td></td><td></td><td>Pinecone</td><td>基于 Faiss 开发的商业版产品</td></tr><tr><td></td><td>开源</td><td>Faiss</td><td>Meta 开源的老牌向量数据库</td></tr><tr><td></td><td></td><td>ChromaDB</td><td>开源向量数据库</td></tr><tr><td></td><td></td><td>Milvus</td><td>开源向量数据库</td></tr><tr><td></td><td></td><td>Weaviate</td><td>开源向量数据库</td></tr><tr><td></td><td></td><td>pgvector</td><td>PostgreSQL 团队推出的开源向量数据库</td></tr><tr><td></td><td></td><td>ElasticSearch</td><td>支持向量数据保存和搜索功能</td></tr></tbody></table><p>Ollama 服务部署了一套与 OpenAI API 兼容的 API，因此可以很简单地使用 OpenAI 官方 SDK 来访问所有 Ollama 部署的 LLM。除了支持 LLM 之外，这套 OpenAI API 兼容的 API 同样也支持嵌入模型，我们可以很简单地使用 OpenAI 官方 SDK 来访问所有 Ollama 部署的嵌入模型。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">ollama</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pull</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> nomic-embed-text</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">ollama</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pull</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> bge-large</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">ollama</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pull</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> bge-m3</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>添加依赖。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~/adh-ai-agent</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> add</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> beautifulsoup4</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> faiss-cpu</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> patchright</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> patchright</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> chromium</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>faiss-cpu 只使用 CPU，不需要独立显卡。另外还有一个 faiss-gpu，这个库和 faiss-cpu 是互相取代的，使用了独立显卡，但是性能会比 faiss-cpu 好很多。</p><p>Patchright 比 Playwright 库更加隐蔽，更不容易被某些网站的反爬虫功能检测到。</p><p>具体实现可以划分为两个大步骤：</p><ol><li>对网页内容做预处理</li></ol><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># reuse the .env file in the adh-ai-agent project</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> adh_ai_agent/rag_with_vecdb.py</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --preprocess</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>回答用户问题</li></ol><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> adh_ai_agent/rag_with_vecdb.py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>在 ADH 后端重新添加 adh-ai-agent 项目作为依赖。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~/awesome-digital-human-live2d/</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -e</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;../adh-ai-agent&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>修改 <code>rag_agent.py</code> 使用新的 RAG 实现方法 <code>from .rag_with_vecdb ...</code>。在 ADH 前端配置新的 AI 智能体，引擎选择 &quot;OutsideAgent&quot;，引擎配置中 agent_type 设置为默认的 &quot;local_lib&quot;，agent_module 设置为 <code>adh_ai_agent.rag_agent</code>。</p><h3 id="agent-sdk-实现-mcp-应用" tabindex="-1"><a class="header-anchor" href="#agent-sdk-实现-mcp-应用"><span>Agent SDK 实现 MCP 应用</span></a></h3><!----><p><a href="https://modelcontextprotocol.io/introduction" target="_blank" rel="noopener noreferrer">MCP</a> 是一个缩写词，全称是 Model Context Protocol，翻译为模型上下文协议。它是由 LLM 一线大厂 Anthroipc 于 2024 年 11 月发布的一个规范。<a href="https://docs.anthropic.com/zh-CN/docs/agents-and-tools/mcp" target="_blank" rel="noopener noreferrer">Anthropic MCP 概述 - 中文文档</a>。</p><blockquote><p>MCP 是一个开放协议，它标准化了应用程序如何向 LLM 提供上下文。可以将 MCP 视为 AI 应用程序的 USB-C 端口。就像 USB-C 为连接设备与各种外设和配件提供了标准化方式一样，MCP 为连接 LLM 与不同数据源和工具提供了标准化方式。</p></blockquote><p>强烈推荐阅读这篇博客 <a href="https://norahsakal.com/blog/mcp-vs-api-model-context-protocol-explained/" target="_blank" rel="noopener noreferrer">What is Model Context Protocol (MCP)? How it simplifies AI integrations compared to APIs</a></p><figure><img src="/devopsme/assets/mcp_overview-BzkANgxZ.png" alt="The Model Context Protocol (MCP) is a standardized protocol that connects AI agents to various external tools and data sources" tabindex="0" loading="lazy"><figcaption>The Model Context Protocol (MCP) is a standardized protocol that connects AI agents to various external tools and data sources</figcaption></figure><p>而传统 API 就像一扇扇门，每扇门都有自己的钥匙和规则。</p><figure><img src="/devopsme/assets/api_overview-bgZ5hws2.png" alt="Traditional APIs require developers to write custom integrations for each service or data source" tabindex="0" loading="lazy"><figcaption>Traditional APIs require developers to write custom integrations for each service or data source</figcaption></figure><p>MCP 的架构支持 MCP 主机通过 MCP 客户端连接多个 MCP 服务器，每个服务器都提供独立的功能，实现了模块化和灵活的集成。MCP 服务器提供了三类公开接口：</p><ul><li>资源访问：允许 LLM 加载数据源，例如本地文件、文档或数据库查询。</li><li>工具调用：支持 LLM 执行特定操作，例如 API 调用或命令执行。</li><li>交互提示：提供可重复使用的 LLM 交互模板，指导 LLM 在特定场景下的行为，提升任务执行的准确性与效率。</li></ul><p>MCP 是非常清晰的分层架构，有效地分离了关注点，大幅降低了 LLM 应用集成外部工具的难度。正是因为 MCP 在整体架构和实现细节两个方面都后来居上超越了 Assistants API，所以才在 AI Agent 开发者社区得到了广泛的欢迎和采用。</p><p>目前已经有很多 AI Agent 开发框架都可以支持 MCP:</p><ul><li><a href="https://openai.github.io/openai-agents-python/mcp/" target="_blank" rel="noopener noreferrer">OpenAI Agent SDK 的 MCP 支持</a></li><li><a href="https://microsoft.github.io/autogen/stable//user-guide/core-user-guide/components/workbench.html" target="_blank" rel="noopener noreferrer">微软 AutoGen 的 MCP 支持</a></li><li><a href="https://google.github.io/adk-docs/tools/mcp-tools/" target="_blank" rel="noopener noreferrer">谷歌 Assistant SDK (ADK) 的 MCP 支持</a></li><li><a href="https://langchain-ai.github.io/langgraph/agents/mcp/" target="_blank" rel="noopener noreferrer">LangGraph 的 MCP 支持</a></li><li><a href="https://docs.llamaindex.ai/en/stable/api_reference/tools/mcp/" target="_blank" rel="noopener noreferrer">LlamaIndex 的 MCP 支持</a></li><li><a href="https://mcp.camel-ai.org/" target="_blank" rel="noopener noreferrer">Camel 的 MCP 支持</a></li></ul><p>与 AI Agent 开发框架支持 MCP 同时，各种各样的 MCP 服务器也在互联网上大量出现，有些甚至是可以免费使用的。<a href="https://developer.aliyun.com/article/1661258" target="_blank" rel="noopener noreferrer">国内最大的 MCP 中文社区来了，4000 多个服务等你体验</a>。</p><p>根据 <a href="https://openai.github.io/openai-agents-python/mcp/" target="_blank" rel="noopener noreferrer">Agent SDK 官方文档</a> 中的介绍，根据不同的传输机制支持使用 3 类 MCP 服务器：</p><ul><li>stdio 服务器：作为应用程序的子进程运行，可视为“本地”运行模式。实现类为 MCPServerStdio。</li><li>HTTP over SSE 服务器：以远程方式运行，需要通过 URL 进行远程连接。实现类为 MCPServerSse。</li><li>支持流式输出的 HTTP 服务器：以远程方式运行，使用 MCP 规范中定义的支持流式输出的 HTTP 传输机制。实现类为 MCPServerStreamableHttp。</li></ul><p>MCP 服务器可被添加到 AI Agent 中。每次运行 AI Agent 时，Agents SDK 都会调用 MCP 服务器的 <code>list_tools()</code> 方法，使 LLM 感知该服务器提供的工具。当 LLM 调用 MCP 服务器的工具时，Agent SDK 会调用该服务器的 <code>call_tool()</code> 方法。</p><p>Agent SDK 官方文档中关于 MCP 的内容只有一个页面。想要了解更多的使用细节，可以阅读 Agent SDK 项目提供的一些<a href="https://github.com/openai/openai-agents-python/tree/main/examples/mcp" target="_blank" rel="noopener noreferrer">端到端的例子</a>。</p><!----><p>为 adh-ai-agent 项目添加一个 Python 依赖：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> add</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;mcp[cli]&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>运行天气预报 MCP Server，运行在本机的 8003 端口，默认只接受来自本机的访问请求。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~/adh-ai-agent</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> adh_ai_agent/weather_mcp_server.py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>MCP host 的代码文件是 <code>adh-ai-agent/adh_ai_agent/weather_mcp_host.py</code>。修改 <code>adh-ai-agent/adh_ai_agent/rag_agent.py</code> 文件，从 weather_mcp_host 中导入 <code>get_jzg_tomorrow_weather</code>，然后重新添加 adh-ai-agent 项目作为依赖。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~/awesome-digital-human-live2d/</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -e</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;../adh-ai-agent&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>重启 ADH 前后端，在 ADH 前端配置新的 AI 智能体，引擎选择 &quot;OutsideAgent&quot;，引擎配置中 agent_type 设置为默认的 &quot;local_lib&quot;，agent_module 设置为 <code>adh_ai_agent.rag_agent</code>。</p><h3 id="openmanus-as-mcp-server" tabindex="-1"><a class="header-anchor" href="#openmanus-as-mcp-server"><span>OpenManus As MCP Server</span></a></h3><p>目前在开源社区已经存在的类 Manus 开发工具有三个：</p><ul><li><a href="https://github.com/FoundationAgents/OpenManus" target="_blank" rel="noopener noreferrer">OpenManus</a>，MetaGPT 团队核心成员开发</li><li><a href="https://github.com/camel-ai/owl" target="_blank" rel="noopener noreferrer">OWL</a>，Camel 团队核心成员开发</li><li><a href="https://github.com/femto/minion-agent" target="_blank" rel="noopener noreferrer">MinionAgent</a>，由郑炳南老师领导的一个小团队开发</li></ul><p>在 GitHub 上最受欢迎的是 OpenManus。在后端服务器上面<a href="https://github.com/FoundationAgents/OpenManus/blob/main/README_zh.md" target="_blank" rel="noopener noreferrer">安装 OpenManus</a>:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> clone</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/FoundationAgents/OpenManus.git</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> OpenManus</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Python&gt;=3.11</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> init</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 3.12</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> venv</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --python</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 3.12</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pip</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -r</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> requirements.txt</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>从配置文件模板复制 OpenManus 的配置文件, <code>cp config/config.example.toml config/config.toml</code>。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 文本大模型</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[llm]</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">model</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;qwen3-8b&quot;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">base_url</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">api_key</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;sk-xxxx&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">...</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 多模态大模型</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[llm.vision]</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">model</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;qwen3-8b&quot;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">base_url</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">api_key</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;sk-xxxx&quot;</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">...</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[browser]</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">headless</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> =</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> true</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用 playwright 安装 Chromium 浏览器。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> playwright</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> chromium</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>qwen3 大模型在使用非 stream 流式输出时，只能工作在非思考模式，这时候必须要传递一个额外的参数 <code>{“enable_thinking”: False}</code>。但是 OpenManus 并不支持传递这个额外的参数，因此运行时就会报错。为了解决这个问题，我们需要修改一下 OpenManus 项目中的 <code>app/llm.py</code>(第 722 行)，添加下面的 if 判断：</p><div class="code-block-with-title"><div class="code-block-title-bar" data-title="app/llm.py"><span>app/llm.py</span></div><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">	            if</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">startswith</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;qwen3&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                params.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">update</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">({</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;extra_body&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: {</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;enable_thinking&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}})</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 721;"><div class="line-number"></div><div class="line-number"></div></div></div></div><p>运行 OpenManus：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> main.py</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 问题：</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 1. 介绍你自己，并将结果保存到 intro.txt</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 2. 搜索豆瓣网站排名前 5 的电影，并将结果保存到 top5_movies.txt</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 生成文件将保存在 OpenManus 项目根目录下的 workspace 目录中。</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>将 OpenManus 作为一个 MCP Server 来调用。在 OpenManus 项目根目录中有两个 Python 文件：</p><ul><li><code>run_mcp.py</code>：和 <code>main.py</code> 差不多，但是以 MCP 协议来调用 OpenManus。</li><li><code>run_mcp_server.py</code>：启动一个 MCP Server，提供给外部程序来调用。</li></ul><p>修改 <code>app/mcp/server.py</code> 以支持远程的 sse server 模式，以便通过 Agent SDK 的 MCP Host 来连接。</p><div class="code-block-with-title"><div class="code-block-title-bar" data-title="app/mcp/server.py"><span>app/mcp/server.py</span></div><div class="language-python" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro has-highlighted vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">class</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;"> MCPServer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &quot;&quot;&quot;MCP Server implementation with tool registration and management.&quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    def</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> __init__</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E5C07B;--shiki-dark-font-style:italic;">self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> name</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> str</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;openmanus&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line highlighted"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        self</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.server </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> FastMCP</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(name, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">port</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">8005</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">......</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> parse_args</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">() -&gt; argparse.Namespace:</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">    &quot;&quot;&quot;Parse command line arguments.&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    parser </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> argparse.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">ArgumentParser</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">description</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;OpenManus MCP Server&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    parser.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">add_argument</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        &quot;--transport&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line highlighted"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">        choices</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;stdio&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;sse&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], </span></span></code></pre></div></div><p>启动 OpenManus 的 MCP Server：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run_mcp_server.py</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --transport</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> sse</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>还需要为这个 MCP Server 编写一个 MCP Host 来调用这个 MCP Server。代码文件是 <code>adh-ai-agent/adh_ai_agent/openmanus_mcp_host.py</code>。执行测试：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ~/adh-ai-agent/</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uv</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> run</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> adh_ai_agent/openmanus_mcp_host.py</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></div><!----><!----><!----></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/JoneyXiao/devopsme/edit/main/src/categories/AI/Digital-Human/Real-time-2D.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">Last Updated:</span><time class="vp-meta-info" datetime="2025-08-22T06:13:40.000Z" data-allow-mismatch>8/22/25, 6:13 AM</time></div><div class="contributors"><span class="vp-meta-label">Contributors: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 87732444@qq.com">Joney Xiao</span><!--]--><!--]--></div></div></footer><!----><div id="comment" class="giscus-wrapper input-top vp-comment" vp-comment style="display:block;"><div style="display: flex;align-items: center;justify-content: center;height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);--icon-size: 48px;display: inline-block;width: var(--icon-size);height: var(--icon-size);background-color: currentcolor;-webkit-mask-image: var(--loading-icon);mask-image: var(--loading-icon)"></span></div></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><!----><div class="vp-copyright">Copyright © 2025 DevOpsMe </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/devopsme/assets/app-D5Np86FI.js" defer></script>
  </body>
</html>
